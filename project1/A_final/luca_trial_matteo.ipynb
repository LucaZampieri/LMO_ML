{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project 1\n",
    "\n",
    "    We begin by loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from preprocessing_functions import *\n",
    "%matplotlib inline \n",
    "import numpy as np   # generic stuff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### REMOVE THIS LINE BEFORE SUBMISSION\n",
    "import pandas as pd\n",
    "#######################################################################\n",
    "\n",
    "from lib.proj1_helpers import * #the helper provided for the project\n",
    "from lib.costs import *\n",
    "\n",
    "# choose which implementations you would like\n",
    "from lib.implementations import *\n",
    "#from implementations import * #our implementations of the functions done by us\n",
    "\n",
    "\n",
    "import datetime\n",
    "from helpers import * #helpers of exo 2\n",
    "# Useful starting lines\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_FOLDER+'train.csv',sub_sample=True)\n",
    "\n",
    "y_test, tx_test, ids_test = load_csv_data(DATA_FOLDER+'test.csv',sub_sample=True)\n",
    "AAA = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that here we are only considering a sub_sample as the \"True\" value indicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ...,  1., -1.,  1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.65702052e+01,   5.02655292e+01,   8.10068096e+01,\n",
       "         5.72432294e+01,  -7.03584253e+02,  -5.96237100e+02,\n",
       "        -7.04529779e+02,   2.37571420e+00,   1.89751598e+01,\n",
       "         1.57925417e+02,   1.44750460e+00,  -1.58575000e-01,\n",
       "        -7.04154751e+02,   3.79714208e+01,  -7.52940000e-03,\n",
       "        -7.32000000e-05,   4.63404222e+01,  -1.99772000e-02,\n",
       "         1.15077200e-01,   4.22103976e+01,   2.86580000e-02,\n",
       "         2.09378977e+02,   9.84400000e-01,  -3.45453367e+02,\n",
       "        -3.96614008e+02,  -3.96605099e+02,  -6.87271262e+02,\n",
       "        -7.04296892e+02,  -7.04330749e+02,   7.36135732e+01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_train\n",
    "np.mean(tx_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219.057</td>\n",
       "      <td>72.461</td>\n",
       "      <td>124.835</td>\n",
       "      <td>5.506</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.771</td>\n",
       "      <td>46.936</td>\n",
       "      <td>122.986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960</td>\n",
       "      <td>90.355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.396</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>50.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.801</td>\n",
       "      <td>27.787</td>\n",
       "      <td>65.373</td>\n",
       "      <td>55.978</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.457</td>\n",
       "      <td>20.608</td>\n",
       "      <td>138.624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880</td>\n",
       "      <td>219.339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.766</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-2.209</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>62.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128.167</td>\n",
       "      <td>52.145</td>\n",
       "      <td>86.912</td>\n",
       "      <td>103.373</td>\n",
       "      <td>0.90</td>\n",
       "      <td>47.636</td>\n",
       "      <td>4.808</td>\n",
       "      <td>2.277</td>\n",
       "      <td>1.936</td>\n",
       "      <td>212.505</td>\n",
       "      <td>...</td>\n",
       "      <td>2.802</td>\n",
       "      <td>292.582</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.406</td>\n",
       "      <td>-2.689</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>31.252</td>\n",
       "      <td>-1.788</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>103.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.067</td>\n",
       "      <td>1.939</td>\n",
       "      <td>70.444</td>\n",
       "      <td>54.621</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.079</td>\n",
       "      <td>30.366</td>\n",
       "      <td>151.198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190</td>\n",
       "      <td>290.199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.634</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>66.634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1        2        3       4        5        6      7       8   \\\n",
       "0  138.470  51.655   97.827   27.980    0.91  124.711    2.666  3.064  41.928   \n",
       "1  219.057  72.461  124.835    5.506 -999.00 -999.000 -999.000  3.771  46.936   \n",
       "2   90.801  27.787   65.373   55.978 -999.00 -999.000 -999.000  2.457  20.608   \n",
       "3  128.167  52.145   86.912  103.373    0.90   47.636    4.808  2.277   1.936   \n",
       "4  107.067   1.939   70.444   54.621 -999.00 -999.000 -999.000  2.079  30.366   \n",
       "\n",
       "        9    ...        20       21   22      23     24     25       26  \\\n",
       "0  197.760   ...    -0.277  258.733  2.0  67.435  2.150  0.444   46.062   \n",
       "1  122.986   ...     0.960   90.355  1.0  50.396 -0.708 -0.642 -999.000   \n",
       "2  138.624   ...     0.880  219.339  1.0  62.766  0.778 -2.209 -999.000   \n",
       "3  212.505   ...     2.802  292.582  2.0  72.406 -2.689 -0.295   31.252   \n",
       "4  151.198   ...     1.190  290.199  1.0  66.634 -0.359 -0.485 -999.000   \n",
       "\n",
       "        27       28       29  \n",
       "0    1.240   -2.475  113.497  \n",
       "1 -999.000 -999.000   50.396  \n",
       "2 -999.000 -999.000   62.766  \n",
       "3   -1.788   -0.287  103.658  \n",
       "4 -999.000 -999.000   66.634  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# illegal: \n",
    "pd.DataFrame(tx_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "Adding powers\n",
      "Adding ones\n"
     ]
    }
   ],
   "source": [
    "deg=9;\n",
    "tx_train,tx_test = prepare_data(tx_train, tx_test, deg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.02794638e-02,   3.33198046e-04,  -1.04006068e-02,\n",
       "         5.95164328e-02,  -3.97333473e-04,   9.01828401e-02,\n",
       "        -2.83900680e-04,  -9.49471673e-04,   1.86900037e-02,\n",
       "         1.32635270e-01,   5.81288413e-04,  -1.07312813e-03,\n",
       "         3.43287150e-04,  -1.13006723e-03,  -1.59894953e-03,\n",
       "         2.77282616e-03,   1.35215996e-02,  -2.36081542e-03,\n",
       "        -2.29997460e-03,   3.03231035e-02,  -2.13106735e-03,\n",
       "         2.04144908e-01,   8.84859057e-04,   4.61426263e-02,\n",
       "        -8.82311692e-04,  -7.35675922e-04,   2.80021898e-02,\n",
       "        -1.29873568e-03,   1.53536038e-03,   1.20244384e-01,\n",
       "         3.04207048e+02,   1.85643822e+03,   1.62274058e+02,\n",
       "        -9.19706518e-01,  -1.68814032e+02,   1.11529528e+00,\n",
       "         2.00417598e+01,   1.23022825e+01,   7.17836219e+02,\n",
       "         2.25169691e+00,   1.34709716e+00,  -2.49138009e-01,\n",
       "         2.84937438e+02,   1.57488313e+00,   1.78512824e-01,\n",
       "         3.44460997e+02,  -1.14050172e+00,   3.26644824e+00,\n",
       "         1.65458728e+02,   3.94553517e-01,   6.32229227e+02,\n",
       "         5.05083403e-01,   7.62175798e+01,  -6.79007126e-01,\n",
       "        -7.37776513e-01,  -2.19787630e+01,  -1.21516137e+00,\n",
       "        -8.45964826e-02,   8.84376706e+01,   3.03066682e+02,\n",
       "        -5.91911890e+02,  -2.99700140e+00,  -9.80078168e+02,\n",
       "         5.78700807e+00,   1.88549872e+00,   5.50449853e+00,\n",
       "        -6.65259831e+02,   9.99223429e+00,  -1.83112310e+01,\n",
       "        -3.84640264e-01,  -1.11071041e+02,   8.67451604e-01,\n",
       "         8.62272905e-01,   2.29318266e+02,   4.94856500e-02,\n",
       "         7.87502349e-01,   2.02872708e+02,  -2.13531260e+00,\n",
       "        -7.99202377e+02,  -8.08916904e+00,  -2.67730479e+02,\n",
       "         2.49859650e-01,   2.62974790e+00,  -4.93364293e+01,\n",
       "         6.44838384e-01,   4.18656057e-01,  -7.83507165e+02,\n",
       "        -1.52344762e+02,  -1.52937165e+00,  -4.93944271e+02,\n",
       "         2.70317440e+00,   1.95364531e+01,   6.33057146e+00,\n",
       "         3.11086566e+02,   2.88121130e+00,  -5.13397279e+00,\n",
       "        -3.39342069e-01,   2.26721815e+02,   5.36837062e-01,\n",
       "         9.27602884e-01,   3.27317557e+02,  -3.80958393e-01,\n",
       "         1.88270943e+00,  -9.37318744e+01,  -9.46354264e-02,\n",
       "         2.23798234e+02,  -1.31074403e+00,  -1.24537375e+02,\n",
       "        -6.19859378e-01,  -4.09223807e-01,  -4.28029709e+01,\n",
       "        -6.65454235e-01,  -2.62020275e-01,  -2.42952722e+02,\n",
       "         2.26189506e+00,   3.84087343e+03,  -9.76432110e+00,\n",
       "        -2.62890859e+01,   4.00211478e+02,   6.11267594e+03,\n",
       "         3.54903618e+00,   4.05442616e+01,  -5.91579165e-01,\n",
       "         5.69159071e+02,   4.83468321e-01,   1.73249523e+00,\n",
       "         4.60968394e+02,   1.44513822e+00,   1.42824543e+00,\n",
       "         1.36851957e+03,   3.91647024e+00,   6.34640314e+03,\n",
       "         3.74187168e+01,   2.36646946e+03,  -1.61704402e-01,\n",
       "        -1.75639396e-01,   4.60523934e+02,  -6.17907164e-01,\n",
       "         3.89997291e-01,   5.08254736e+03,   1.66558394e+02,\n",
       "        -1.58115569e+00,  -1.94958816e-02,  -1.98123964e+00,\n",
       "         2.41338885e+00,  -4.66625696e-02,   1.20278329e-01,\n",
       "         1.23153166e-01,   7.63531890e-01,   1.01732675e-02,\n",
       "        -2.04545307e-02,  -9.51508803e-01,   1.06260416e-02,\n",
       "         2.60048404e-02,  -4.15048067e-01,   4.39337205e-02,\n",
       "        -8.23042756e-01,   7.17348451e-02,   5.74286543e-01,\n",
       "         2.31510893e-02,  -2.28792475e-02,  -7.68108301e-01,\n",
       "         2.40843822e-02,  -4.02201334e-02,   2.60136199e+00,\n",
       "        -3.30298589e+02,  -2.75847839e+01,   2.61048386e+02,\n",
       "         8.80969539e+03,  -1.07822946e+01,   4.74818337e+01,\n",
       "         1.96539517e+01,   7.46046824e+02,  -6.79326707e-01,\n",
       "        -2.54116952e+00,   1.41883318e+02,   2.23467522e+00,\n",
       "         7.22382396e+00,   1.27820141e+03,   8.44733445e+00,\n",
       "         8.05854359e+03,   5.41060845e+01,   3.47209086e+03,\n",
       "        -3.54736009e+00,  -5.37417008e+00,   1.32190471e+03,\n",
       "         7.36294387e+00,  -8.28275701e+00,   7.92176215e+03,\n",
       "         7.47246797e-02,   2.85013803e+00,  -1.46869309e+01,\n",
       "         1.07611707e-01,  -2.23516151e-01,  -2.29795638e-01,\n",
       "        -2.60571274e+00,  -3.50973943e-02,   1.52223729e-02,\n",
       "         1.33695256e+00,  -4.55993668e-02,  -6.16232470e-02,\n",
       "        -2.03956330e+00,  -6.62170419e-02,  -9.69278546e+00,\n",
       "        -1.31157712e-01,  -6.02346278e+00,  -6.15368869e-02,\n",
       "         2.74653386e-02,  -1.23640967e+00,  -5.14257799e-02,\n",
       "         1.32205893e-01,  -1.34181715e+01,  -2.66654009e+00,\n",
       "        -3.92471848e+01,   3.75981772e-02,  -2.03435889e-01,\n",
       "         3.79017081e-03,  -3.50176223e+00,   1.40303673e-03,\n",
       "        -6.76578204e-03,  -9.73192784e-01,  -1.46473007e-02,\n",
       "        -6.44785245e-03,  -9.68358732e+00,  -2.66295944e-02,\n",
       "        -4.04991015e+01,  -2.59545972e-01,  -1.58564310e+01,\n",
       "        -5.63670356e-03,  -1.07400796e-02,  -3.23775085e+00,\n",
       "        -4.17597739e-03,  -2.07318063e-03,  -3.47722273e+01,\n",
       "         1.06960580e+03,   7.49346655e-02,   4.47688582e+00,\n",
       "        -5.57517327e-01,   6.53161593e+01,  -2.30505103e-01,\n",
       "        -1.46073601e-02,   4.56374242e+01,  -5.18125167e-02,\n",
       "         1.03986158e-01,   1.44307991e+02,  -3.47192325e-01,\n",
       "         1.34568605e+03,   8.02430656e+00,   2.64755870e+02,\n",
       "        -7.13980427e-01,  -3.77090991e-01,   1.37575841e+02,\n",
       "         5.46240606e-01,   4.67622035e-01,   9.58652179e+02,\n",
       "         7.09461634e+00,   5.88353960e+01,  -1.92761275e+00,\n",
       "         1.23187549e+03,  -1.06300038e+00,   1.94990347e+00,\n",
       "         1.03893049e+03,   1.46597993e+00,   3.18958744e+00,\n",
       "         1.98613208e+03,   5.68405328e+00,   1.36697255e+04,\n",
       "         8.54199198e+01,   4.60714301e+03,  -6.34138295e-01,\n",
       "        -2.37179891e-01,   1.39114810e+03,  -1.07108646e+00,\n",
       "         1.21412159e+00,   1.13605612e+04,  -5.71743692e-02,\n",
       "        -4.04278954e-03,  -8.62021180e+00,   8.77937803e-03,\n",
       "         5.32485988e-02,   1.26797638e+01,  -1.22134924e-02,\n",
       "        -2.18711292e-02,   7.80349784e-01,  -1.27279464e-02,\n",
       "         2.68608463e+00,   2.79871838e-02,   1.70221500e+00,\n",
       "        -1.66351252e-02,   1.21622602e-02,  -7.36954931e-02,\n",
       "         1.74198901e-02,   2.42641948e-02,   3.03506574e+00,\n",
       "         9.27356731e-03,   4.11057406e+00,   9.93248987e-03,\n",
       "         2.06222066e-02,   1.07170459e+00,   3.48609320e-02,\n",
       "        -3.90212733e-03,   6.80780512e+00,   5.65855764e-02,\n",
       "         6.50780912e+01,   5.70159687e-01,   1.67812012e+01,\n",
       "        -1.39005376e-02,  -2.25156475e-02,   3.30316115e+00,\n",
       "         3.88437578e-03,   1.29630129e-02,   5.36531129e+01,\n",
       "        -9.98472072e-02,   2.24366802e-03,   1.07105781e-03,\n",
       "        -1.41224107e-01,   2.80070637e-03,  -1.96624713e-03,\n",
       "        -4.10834277e-01,  -1.65133146e-03,  -2.45248645e+00,\n",
       "        -1.94197633e-02,  -3.30479174e-01,   1.29977073e-03,\n",
       "        -7.49831342e-03,  -1.08198258e-01,  -3.48651931e-04,\n",
       "        -4.35035195e-03,  -1.68654154e+00,  -7.26741242e-02,\n",
       "        -2.05606885e-01,   3.42089946e+01,   2.91207851e-01,\n",
       "         1.36619371e+00,   1.33639575e+02,   8.77647457e-01,\n",
       "         1.26442444e+03,   4.72124736e+00,   3.78868137e+02,\n",
       "         2.21865930e-01,  -5.85601142e-02,   7.89964803e+01,\n",
       "        -3.46062255e-01,  -7.21273805e-01,   7.60996592e+02,\n",
       "         4.52566673e-03,   1.43939305e-01,   8.44303342e-01,\n",
       "         2.92764437e-02,   4.99848761e-01,  -1.61098386e-02,\n",
       "        -2.72383957e+00,  -2.15211932e-02,   1.15318665e-01,\n",
       "         2.90428814e-01,   2.25163899e-02,  -1.38353822e-01,\n",
       "         1.23016232e-01,  -1.99108216e-02,  -1.13425234e+00,\n",
       "         1.09902360e+00,   2.12753604e-02,  -7.21758644e-01,\n",
       "         9.31585819e-02,   8.38820756e-02,   1.64083719e+00,\n",
       "        -6.04534661e-03,   1.51830880e+00,   5.84520363e-02,\n",
       "        -3.30793373e-01,   1.38693510e-01,   4.61788454e-03,\n",
       "        -7.91829442e-02,   1.05648891e+00,  -2.10936284e-01,\n",
       "         6.74100621e-01,   1.13031102e+02,   6.07220779e-01,\n",
       "         9.21391819e+02,   3.77604020e+00,   2.86225224e+02,\n",
       "        -4.09933442e-01,  -1.42438958e-01,   4.45712451e+01,\n",
       "         1.46608248e-01,   3.78143138e-01,   5.58940248e+02,\n",
       "        -1.53824274e-02,   4.71019521e-01,   6.62778913e-03,\n",
       "         1.10898102e+00,   1.12358669e-02,   1.74614785e-01,\n",
       "         3.25152008e-01,  -1.97910009e-02,   2.91950119e-01,\n",
       "         1.28962737e-01,  -3.31658451e-02,   1.38570003e+00,\n",
       "         6.27830421e-01,   6.10201926e-02,   2.88015180e+00,\n",
       "         2.98890575e-03,   9.58058174e-01,   5.16457295e-02,\n",
       "        -5.51409489e-01,  -2.67564851e-02,   4.78059874e-02,\n",
       "        -1.45385061e-01,   1.14928614e+00,   2.76219958e-01,\n",
       "         2.03114439e+03,   9.60581526e+00,   9.69379616e+02,\n",
       "        -3.21173006e-01,   1.11616491e+00,   1.86249472e+02,\n",
       "        -5.08666547e-01,   3.82663539e-01,   1.73946071e+03,\n",
       "         5.54641490e+00,   4.34308900e-02,   1.73396124e+00,\n",
       "         6.28927103e-02,  -6.03452274e-01,  -1.26739745e-01,\n",
       "         1.90578098e-02,  -8.10481155e-02,   4.19919759e+00,\n",
       "         8.75643818e+01,   4.56457050e+03,   2.51624450e+00,\n",
       "         1.58774339e+00,   1.40974895e+03,  -4.46613659e-01,\n",
       "         2.18722829e+00,   1.14839073e+04,   1.65994416e+01,\n",
       "        -6.73372265e-03,   3.33590506e-03,   5.58121445e+00,\n",
       "         1.22724021e-02,   2.77626725e-02,   7.69226206e+01,\n",
       "        -3.44156295e-01,  -4.56156914e-01,   5.01641221e+02,\n",
       "        -9.93530625e-01,   4.35571836e-01,   3.94204873e+03,\n",
       "        -6.76488261e-02,   1.25427273e-01,  -2.30759300e-01,\n",
       "        -2.71046282e-02,  -4.46077036e-01,   2.79707460e-01,\n",
       "         2.59579487e-03,  -8.07853859e-02,  -3.61863126e-02,\n",
       "        -3.82935194e-01,  -1.51168916e-02,   1.26758009e+03,\n",
       "        -5.52884674e-02,  -8.71632990e-01,   1.55725304e+00,\n",
       "         2.96941776e+03,   7.89836733e+05,   4.38918758e+08,\n",
       "         2.87385332e+11,   2.09072944e+14,   1.59947796e+17,\n",
       "         1.25987404e+20,   1.01098918e+23,   1.23190726e+03,\n",
       "         3.40504789e+04,   7.12133134e+06,   7.08836762e+08,\n",
       "         1.35785140e+11,   1.75612671e+13,   3.89350402e+15,\n",
       "         5.11558092e+17,   1.70810806e+03,   2.66531723e+05,\n",
       "         9.25511391e+07,   3.74582826e+10,   1.71458703e+13,\n",
       "         8.35514247e+15,   4.23600069e+18,   2.20683513e+21,\n",
       "         3.94085169e+03,   5.49089290e+05,   1.63073972e+08,\n",
       "         5.27216066e+10,   1.99128715e+13,   8.21285306e+15,\n",
       "         3.60233438e+18,   1.64723500e+21,   9.00177109e-01,\n",
       "         1.37720993e+00,   7.38520647e+00,   2.22975654e+01,\n",
       "         1.02232463e+02,   3.93418089e+02,   1.83625821e+03,\n",
       "         7.75771240e+03,   4.91169269e+04,   5.49906222e+07,\n",
       "         9.05077303e+10,   1.73164627e+14,   3.69247045e+17,\n",
       "         8.42494528e+20,   2.00914305e+24,   4.93646493e+27,\n",
       "         3.91170344e+00,  -7.20154368e+00,   2.38357813e+02,\n",
       "        -5.38441251e+02,   2.52517906e+04,  -3.48802282e+04,\n",
       "         3.55560656e+06,   1.27578865e+06,   6.25855157e-01,\n",
       "        -8.24219159e-02,   1.10176519e+00,   1.33844719e-01,\n",
       "         3.36172704e+00,   2.78071324e+00,   1.50503647e+01,\n",
       "         2.45887578e+01,   4.95180776e+02,   3.18101304e+04,\n",
       "         4.49849974e+06,   7.18649372e+08,   1.29249316e+11,\n",
       "         2.48056398e+13,   4.97296777e+15,   1.02866035e+18,\n",
       "         1.36313694e+04,   3.87502981e+06,   2.31445677e+09,\n",
       "         1.57356086e+12,   1.26587063e+15,   1.12640211e+18,\n",
       "         1.07136778e+21,   1.06348224e+24,   7.04332442e-01,\n",
       "         1.37947982e+00,   7.03338265e+00,   3.82083974e+01,\n",
       "         2.41838938e+02,   1.64592633e+03,   1.17893898e+04,\n",
       "         8.74606882e+04,   1.40008645e+00,   3.28740808e-01,\n",
       "         2.50691200e+00,   1.35840268e+00,   5.27383234e+00,\n",
       "         5.45828561e+00,   1.67662028e+01,   3.53735683e+01,\n",
       "         4.83758149e-02,  -2.10482270e-03,   1.37714330e-02,\n",
       "         6.33858469e-03,   1.78772927e-02,   3.18315227e-02,\n",
       "         6.70086739e-02,   1.37249189e-01,   4.36669739e+02,\n",
       "         2.91518179e+04,   4.25457888e+06,   7.71000288e+08,\n",
       "         1.64720619e+11,   3.83954275e+13,   9.39474290e+15,\n",
       "         2.36155906e+18,   1.50582833e+00,  -3.04371622e-01,\n",
       "         7.86149269e+00,  -3.56165906e+01,   4.17823969e+02,\n",
       "        -4.47807034e+03,   5.03296788e+04,  -5.63781280e+05,\n",
       "         3.21967609e+00,   3.24312827e-01,   1.98100768e+01,\n",
       "         1.13947685e+01,   2.15322256e+02,   7.44555111e+02,\n",
       "         7.34329230e+03,   5.50305032e+04,   4.45781100e+02,\n",
       "         2.47015180e+04,   2.85593282e+06,   3.75606580e+08,\n",
       "         5.77448442e+10,   9.77886740e+12,   1.77301232e+15,\n",
       "         3.37193329e+17,   1.61449228e+00,  -2.36071368e-02,\n",
       "         5.51358910e+00,  -1.52542956e+00,   3.21531508e+01,\n",
       "        -6.64335763e+01,   5.17072616e+02,  -2.59717178e+03,\n",
       "         3.36440598e+00,  -6.67308153e-01,   2.20229204e+01,\n",
       "        -2.55441117e+01,   3.29757382e+02,  -1.91655210e+03,\n",
       "         1.92918228e+04,  -1.80411630e+05,   1.03291897e+03,\n",
       "         9.73968711e+04,   2.08140648e+07,   5.11648300e+09,\n",
       "         1.44145343e+12,   4.34481067e+14,   1.36490916e+17,\n",
       "         4.40398120e+19,   3.26661064e+00,  -1.53728670e-01,\n",
       "         2.03957004e+01,  -1.02496536e+01,   2.19978056e+02,\n",
       "        -7.30925688e+02,   7.30207976e+03,  -5.41425201e+04,\n",
       "         1.67165090e+04,   4.33162539e+06,   2.84553143e+09,\n",
       "         1.94927594e+12,   1.62766969e+15,   1.50734787e+18,\n",
       "         1.50309185e+21,   1.57041610e+24,   9.52984659e-01,\n",
       "         5.67418714e-01,   2.11216381e+00,   3.16821529e+00,\n",
       "         8.40928424e+00,   2.09862328e+01,   6.80055879e+01,\n",
       "         2.51491957e+02,   2.37599272e+03,   4.35747342e+05,\n",
       "         1.45556867e+08,   6.05119965e+10,   2.99410035e+13,\n",
       "         1.64772439e+16,   9.67649934e+18,   5.91185711e+21,\n",
       "         1.93946978e+00,  -9.96745266e-02,   1.39647120e+01,\n",
       "        -9.37384986e-01,   1.34690859e+02,  -6.69311112e+00,\n",
       "         1.54039279e+03,  -2.53921275e+00,   1.96830507e+00,\n",
       "         5.71273742e-02,   1.16696718e+01,   3.35956274e-01,\n",
       "         8.24917055e+01,   1.94823208e+00,   6.34329300e+02,\n",
       "         1.29541815e+01,   3.53645220e+02,   4.33950865e+04,\n",
       "         8.52144929e+06,   2.01408547e+09,   5.29058368e+11,\n",
       "         1.46925915e+14,   4.20855130e+16,   1.22763642e+19,\n",
       "         1.21150084e+00,   7.59460834e-02,   1.11210302e+01,\n",
       "        -4.62239393e+00,   1.73276787e+02,  -4.52145488e+02,\n",
       "         5.50506203e+03,  -3.26114303e+04,   9.73946231e-01,\n",
       "         3.04895779e-01,   6.53336197e+00,   9.59351557e+00,\n",
       "         9.82892406e+01,   4.98877487e+02,   4.14864857e+03,\n",
       "         3.14587919e+04,   1.00406225e+04,   2.64157581e+06,\n",
       "         1.50002480e+09,   1.01307721e+12,   8.08412103e+14,\n",
       "         7.07692033e+17,   6.54704510e+20,   6.26013111e+23,\n",
       "         1.00000000e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tx_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 706)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_w = np.zeros(tx_train.shape[1])\n",
    "initial_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.05\n",
    "max_iters = 1000\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT_FOLDER = 'output/'\n",
    "\n",
    "def func_least_squares (y, tx, test_set, fct='mse'):\n",
    "    name = 'least_squares'\n",
    "    w,loss = least_squares(y,tx,fct)\n",
    "    y_pred = predict_labels(w, test_set)\n",
    "    create_csv_submission(ids_test, y_pred, OUT_FOLDER+name)\n",
    "    \n",
    "    plt.plot(w, 'go')\n",
    "    plt.title('least squares weights for loss:  '+str(loss),fontsize=15, fontweight='bold');\n",
    "    plt.show()\n",
    "    \n",
    "    return w, loss\n",
    "\n",
    "def func_GD (y, tx, test_set, max_iters, gamma, initial_w):\n",
    "    name = 'Gradient_descent'\n",
    "    w,loss = least_squares_GD(y, tx, initial_w, max_iters, gamma,fct='mse');\n",
    "    y_pred = predict_labels(w, test_set)\n",
    "    create_csv_submission(ids_test, y_pred, OUT_FOLDER+name)\n",
    "    \n",
    "    plt.plot(w, 'go')\n",
    "    plt.title('GD: weights with loss:  '+str(loss),fontsize=15, fontweight='bold');\n",
    "    plt.show()\n",
    "    \n",
    "    return w, loss\n",
    "\n",
    "########################  RIDGE REGRESSION #######################################################\n",
    "def func_ridge_regression (y, tx, test_set, lambda_):\n",
    "    name = 'Ridge_regression'\n",
    "    \n",
    "    w,loss = ridge_regression(y, tx, lambda_=lambda_, fct='mse');\n",
    "    \n",
    "    y_pred = predict_labels(w, test_set)\n",
    "    create_csv_submission(ids_test, y_pred, OUT_FOLDER+name)\n",
    "    \n",
    "    plt.plot(w, 'go')\n",
    "    plt.title('Ridge regression: weights ;loss:  '+str(loss),fontsize=15, fontweight='bold');\n",
    "    plt.show()\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEAST-SQUARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEKCAYAAABOjWFfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlYKTlhmZlYKTlhmZlYKTlhmZlYK/x9YYg9VW76VxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109698160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w, loss = func_least_squares (y=y_train, tx=tx_train, test_set=tx_test, fct='mse');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.460000000000008"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = predict_labels(w, tx_train)\n",
    "right_train = np.sum(y_pred_train == y_train)/len(y_train)*100\n",
    "right_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/499): loss=0.5000000000000004, w0=0.07865693408977247, w1=-1.174452544260258\n",
      "Gradient Descent(1/499): loss=3.2185262255688604e+111, w0=-2.1883188450052752e+54, w1=8.402427347023627e+54\n",
      "Gradient Descent(2/499): loss=2.586811580888404e+226, w0=6.203895641523393e+111, w1=-2.3820925603231666e+112\n",
      "Gradient Descent(3/499): loss=inf, w0=-1.7588076903872944e+169, w1=6.753244987341451e+169\n",
      "Gradient Descent(4/499): loss=inf, w0=4.986229089768977e+226, w1=-1.9145485200149164e+227\n",
      "Gradient Descent(5/499): loss=inf, w0=-1.4135985799666138e+284, w1=5.427755164164871e+284\n",
      "Gradient Descent(6/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(7/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(8/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(9/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(10/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(11/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(12/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(13/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(14/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(15/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(16/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(17/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(18/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(19/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(20/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(21/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(22/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(23/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(24/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(25/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(26/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(27/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(28/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(29/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(30/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(31/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(32/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(33/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(34/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(35/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(36/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(37/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(38/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(39/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(40/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(41/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(42/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(43/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(44/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(45/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(46/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(47/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(48/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(49/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(50/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(51/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(52/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(53/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(54/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(55/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(56/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(57/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(58/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(59/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(60/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(61/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(62/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(63/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(64/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(65/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(66/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(67/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(68/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(69/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(70/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(71/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(72/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(73/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(74/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(75/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(76/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(77/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(78/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(79/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(80/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(81/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(82/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(83/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(84/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(85/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(86/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(87/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(88/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(89/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(90/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(91/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(92/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(93/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(94/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(95/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(96/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(97/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(98/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(99/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(100/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(101/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(102/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(103/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(104/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(105/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(106/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(107/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(108/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(109/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(110/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(111/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(112/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(113/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(114/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(115/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(116/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(117/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(118/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(119/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(120/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(121/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(122/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(123/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(124/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(125/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(126/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(127/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(128/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(129/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(130/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(131/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(132/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(133/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(134/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(135/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(136/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(137/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(138/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(139/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(140/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(141/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(142/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(143/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(144/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(145/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(146/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(147/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(148/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(149/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(150/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(151/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(152/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(153/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(154/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(155/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(156/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(157/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(158/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(159/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(160/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(161/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(162/499): loss=nan, w0=nan, w1=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(163/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(164/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(165/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(166/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(167/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(168/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(169/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(170/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(171/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(172/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(173/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(174/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(175/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(176/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(177/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(178/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(179/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(180/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(181/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(182/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(183/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(184/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(185/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(186/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(187/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(188/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(189/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(190/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(191/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(192/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(193/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(194/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(195/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(196/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(197/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(198/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(199/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(200/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(201/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(202/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(203/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(204/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(205/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(206/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(207/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(208/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(209/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(210/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(211/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(212/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(213/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(214/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(215/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(216/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(217/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(218/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(219/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(220/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(221/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(222/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(223/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(224/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(225/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(226/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(227/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(228/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(229/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(230/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(231/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(232/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(233/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(234/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(235/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(236/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(237/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(238/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(239/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(240/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(241/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(242/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(243/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(244/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(245/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(246/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(247/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(248/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(249/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(250/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(251/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(252/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(253/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(254/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(255/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(256/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(257/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(258/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(259/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(260/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(261/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(262/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(263/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(264/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(265/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(266/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(267/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(268/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(269/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(270/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(271/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(272/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(273/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(274/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(275/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(276/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(277/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(278/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(279/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(280/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(281/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(282/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(283/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(284/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(285/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(286/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(287/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(288/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(289/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(290/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(291/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(292/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(293/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(294/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(295/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(296/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(297/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(298/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(299/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(300/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(301/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(302/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(303/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(304/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(305/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(306/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(307/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(308/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(309/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(310/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(311/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(312/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(313/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(314/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(315/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(316/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(317/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(318/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(319/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(320/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(321/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(322/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(323/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(324/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(325/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(326/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(327/499): loss=nan, w0=nan, w1=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(328/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(329/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(330/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(331/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(332/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(333/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(334/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(335/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(336/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(337/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(338/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(339/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(340/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(341/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(342/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(343/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(344/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(345/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(346/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(347/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(348/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(349/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(350/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(351/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(352/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(353/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(354/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(355/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(356/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(357/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(358/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(359/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(360/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(361/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(362/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(363/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(364/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(365/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(366/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(367/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(368/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(369/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(370/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(371/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(372/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(373/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(374/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(375/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(376/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(377/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(378/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(379/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(380/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(381/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(382/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(383/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(384/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(385/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(386/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(387/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(388/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(389/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(390/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(391/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(392/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(393/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(394/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(395/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(396/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(397/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(398/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(399/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(400/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(401/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(402/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(403/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(404/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(405/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(406/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(407/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(408/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(409/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(410/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(411/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(412/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(413/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(414/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(415/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(416/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(417/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(418/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(419/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(420/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(421/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(422/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(423/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(424/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(425/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(426/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(427/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(428/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(429/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(430/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(431/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(432/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(433/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(434/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(435/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(436/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(437/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(438/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(439/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(440/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(441/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(442/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(443/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(444/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(445/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(446/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(447/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(448/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(449/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(450/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(451/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(452/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(453/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(454/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(455/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(456/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(457/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(458/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(459/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(460/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(461/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(462/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(463/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(464/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(465/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(466/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(467/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(468/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(469/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(470/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(471/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(472/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(473/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(474/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(475/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(476/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(477/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(478/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(479/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(480/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(481/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(482/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(483/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(484/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(485/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(486/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(487/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(488/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(489/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(490/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(491/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(492/499): loss=nan, w0=nan, w1=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(493/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(494/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(495/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(496/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(497/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(498/499): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(499/499): loss=nan, w0=nan, w1=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteociprian/Documents/GitHub/LMO_ML/project1/A_final/lib/proj1_helpers.py:30: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= 0)] = -1\n",
      "/Users/matteociprian/Documents/GitHub/LMO_ML/project1/A_final/lib/proj1_helpers.py:31: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > 0)] = 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cf1cefd1cab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_GD\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-f830c63a93f5>\u001b[0m in \u001b[0;36mfunc_GD\u001b[0;34m(y, tx, test_set, max_iters, gamma, initial_w)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_FOLDER\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'go'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/matteociprian/Documents/GitHub/LMO_ML/project1/A_final/lib/proj1_helpers.py\u001b[0m in \u001b[0;36mcreate_csv_submission\u001b[0;34m(ids, y_pred, name)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "w, loss = func_GD (y=y_train, tx=tx_train, test_set=tx_test, max_iters=500,gamma=0.1, initial_w=initial_w);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape\n",
    "tx_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.495599999999996"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = predict_labels(w, tx_train)\n",
    "right_train = np.sum(y_pred_train == y_train)/len(y_train)*100\n",
    "right_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEKCAYAAAB+AXB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUphgMwzDMCrF/w9+ACkrNCwq8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185502940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[w,loss]=func_ridge_regression (y=y_train, tx=tx_train, test_set=tx_test, lambda_=lambda_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.280000000000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = predict_labels(w, tx_train)\n",
    "right_train = np.sum(y_pred_train == y_train)/len(y_train)*100\n",
    "right_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func_SGD (y, tx, test_set, max_iters, gamma, initial_w, batch_size):\n",
    "    name = 'Stochastic_Gradient_descent'\n",
    "    \n",
    "    w,loss = least_squares_SGD(y, tx, initial_w, max_iters,\\\n",
    "                               gamma, batch_size)\n",
    "    \n",
    "    y_pred = predict_labels(w, test_set)\n",
    "    create_csv_submission(ids_test, y_pred, OUT_FOLDER+name)\n",
    "    \n",
    "    plt.plot(w, 'go')\n",
    "    plt.title('SGD: weights with loss:  '+str(loss),fontsize=15, fontweight='bold');\n",
    "    plt.show()\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteociprian/Documents/GitHub/LMO_ML/project1/A_final/lib/proj1_helpers.py:30: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= 0)] = -1\n",
      "/Users/matteociprian/Documents/GitHub/LMO_ML/project1/A_final/lib/proj1_helpers.py:31: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > 0)] = 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6dd1dfc24b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_SGD\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-edb198be44b4>\u001b[0m in \u001b[0;36mfunc_SGD\u001b[0;34m(y, tx, test_set, max_iters, gamma, initial_w, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_FOLDER\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'go'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/matteociprian/Documents/GitHub/LMO_ML/project1/A_final/lib/proj1_helpers.py\u001b[0m in \u001b[0;36mcreate_csv_submission\u001b[0;34m(ids, y_pred, name)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "w, loss = func_SGD (y=y_train, tx=tx_train, test_set=tx_test, max_iters=10,gamma=gamma, initial_w=initial_w,\\\n",
    "                   batch_size=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def cross_validation_logistic_regression(y,tx, k_fold, max_iters, gammas):\n",
    "    \n",
    "    accuracies=np.zeros(len(gammas))\n",
    "    acc_max=0;\n",
    "    gamma_best=0;\n",
    "    \n",
    "    for i, single_gamma in enumerate(gammas):\n",
    "        \n",
    "        seed=1;\n",
    "\n",
    "        # get k'th subgroup in test, others in train\n",
    "        k_indices = build_k_indices(y, k_fold, seed)\n",
    "        accuracy_train = np.zeros(k_fold)\n",
    "        accuracy_test = np.zeros(k_fold)\n",
    "\n",
    "\n",
    "        for k in range(k_fold):\n",
    "            #print('----- FOLD', k, '-----')\n",
    "            k_index = k_indices[k]\n",
    "            test_y = y[k_index]\n",
    "            test_tx = tx[k_index,:]\n",
    "\n",
    "            mask = np.ones(len(y), dtype=bool) # set all elements to True\n",
    "            mask[k_index] = False              # set test elements to False\n",
    "            train_tx = tx[mask,:]              # select only True elements (ie train elements)\n",
    "            train_y = y[mask]\n",
    "            weights,loss = logistic_regression(train_y, train_tx, initial_w, max_iters, single_gamma)\n",
    "            # Compute the predictions\n",
    "            y_pred_train = predict_labels(weights, train_tx)\n",
    "            y_pred_test = predict_labels(weights, test_tx)\n",
    "            predictions=True;\n",
    "            accuracy_train[k] = np.sum(y_pred_train == train_y)/len(train_y)\n",
    "            accuracy_test[k] = np.sum(y_pred_test == test_y)/len(test_y)\n",
    "        accuracies[i]=np.mean(accuracy_test);\n",
    "        \n",
    "        print('GAMMA:', single_gamma, '---','ACCURANCY:',accuracies[i])\n",
    "        if (accuracies[i]>acc_max):\n",
    "                gamma_best=gammas[i];\n",
    "                acc_max=accuracies[i];\n",
    "    \n",
    "    return gamma_best,acc_max\n",
    "               \n",
    "        # Compute accuracy of the predictions\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAMMA: 1e-05 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.100008888889 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.200007777778 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.300006666667 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.400005555556 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.500004444444 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.600003333333 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.700002222222 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.800001111111 --- ACCURANCY: 0.4644\n",
      "GAMMA: 0.9 --- ACCURANCY: 0.4644\n",
      "BEST GAMMA: 1e-05 --- ACCURANCY: 0.4644\n"
     ]
    }
   ],
   "source": [
    "gammas=np.linspace(0.00001,0.9,10);\n",
    "k_fold=2;\n",
    "max_iters=1000;\n",
    "\n",
    "best_gamma,acc_max=cross_validation_logistic_regression(y_train,tx_train, k_fold, max_iters, gammas)\n",
    "print('BEST GAMMA:', best_gamma, '---','ACCURANCY:',acc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func_logistic (y, tx, test_set, max_iters, gamma, initial_w):\n",
    "    name = 'Logistic regression'\n",
    "    \n",
    "    #w,loss = logistic_regression(y, tx, initial_w, max_iters, gamma)\n",
    "    w,loss = logistic_regression(y, tx, initial_w, max_iters, gamma)\n",
    "    \n",
    "    loss=loss/len(y);\n",
    "    y_pred = predict_labels(w, test_set)\n",
    "    create_csv_submission(ids_test, y_pred, OUT_FOLDER+name)  \n",
    "    \n",
    "    plt.plot(w, 'go')\n",
    "    plt.title('logistic reg: weights with loss:  '+str(loss),fontsize=15, fontweight='bold');\n",
    "    plt.show()\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdIAAAEKCAYAAACmDdR0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x179b34c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w, loss = func_logistic (y=y_train, tx=tx_train, test_set=tx_test, max_iters=1000,\\\n",
    "                         gamma=best_gamma, initial_w=initial_w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.019999999999996"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = predict_labels(w, tx_train)\n",
    "right_train = np.sum(y_pred_train == y_train)/len(y_train)*100\n",
    "right_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGULARIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def cross_validation_logistic_regression_reg(y,tx, k_fold, max_iters, gammas,lambdas):\n",
    "    \n",
    "    acc_max=0;\n",
    "    accurancies=np.zeros([len(gammas),len(lambdas)]);\n",
    "    for i, single_gamma in enumerate(gammas):\n",
    "        for j, single_lambda in enumerate(lambdas):\n",
    "            seed=1;\n",
    "        \n",
    "            # get k'th subgroup in test, others in train\n",
    "            k_indices = build_k_indices(y, k_fold, seed)\n",
    "            accuracy_train = np.zeros(k_fold)\n",
    "            accuracy_test = np.zeros(k_fold)\n",
    "\n",
    "\n",
    "            for k in range(k_fold):\n",
    "                #print('----- FOLD', k, '-----')\n",
    "                k_index = k_indices[k]\n",
    "                test_y = y[k_index]\n",
    "                test_tx = tx[k_index,:]\n",
    "\n",
    "                mask = np.ones(len(y), dtype=bool) # set all elements to True\n",
    "                mask[k_index] = False              # set test elements to False\n",
    "                train_tx = tx[mask,:]              # select only True elements (ie train elements)\n",
    "                train_y = y[mask]\n",
    "                weights,loss = logistic_regression(train_y, train_tx, initial_w, max_iters, single_gamma)\n",
    "                # Compute the predictions\n",
    "                y_pred_train = predict_labels(weights, train_tx)\n",
    "                y_pred_test = predict_labels(weights, test_tx)\n",
    "                predictions=True;\n",
    "                accuracy_train[k] = np.sum(y_pred_train == train_y)/len(train_y)\n",
    "                accuracy_test[k] = np.sum(y_pred_test == test_y)/len(test_y)\n",
    "            accurancies[i,j]= np.mean(accuracy_test);\n",
    "            print('GAMMA', single_gamma, '---','LAMBDA', single_lambda, '---ACCURANCY:',accurancies[i,j])\n",
    "            \n",
    "            if (accurancies[i,j]>acc_max):\n",
    "                gamma_best=gammas[i];\n",
    "                lambda_best=lambdas[j];\n",
    "                acc_max=accurancies[i,j];\n",
    "            \n",
    "            \n",
    "    return [gamma_best,lambda_best,acc_max]\n",
    "     \n",
    "    \n",
    "    \n",
    "            # Compute accuracy of the predictions\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAMMA 1e-06 --- LAMBDA 0.001 ---ACCURANCY: 0.7034\n",
      "GAMMA 1e-06 --- LAMBDA 0.3 ---ACCURANCY: 0.7034\n",
      "GAMMA 0.0001 --- LAMBDA 0.001 ---ACCURANCY: 0.713864\n",
      "GAMMA 0.0001 --- LAMBDA 0.3 ---ACCURANCY: 0.713864\n",
      "BEST GAMMA 0.0001 --- BEST LAMBDA 0.001 ---ACCURANCY: 0.713864\n"
     ]
    }
   ],
   "source": [
    "#test cross_validation\n",
    "\n",
    "gammas=np.linspace(0.000001,0.0001,2);\n",
    "lambdas=np.linspace(0.001,0.3,2);\n",
    "k_fold=2;\n",
    "max_iters=10;\n",
    "[gamma_best,lambda_best,acc_max]= cross_validation_logistic_regression_reg(y_train,tx_train, k_fold, max_iters, gammas,lambdas)\n",
    "\n",
    "print('BEST GAMMA', gamma_best, '---','BEST LAMBDA', lambda_best, '---ACCURANCY:',acc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func_logistic_reg (y, tx, lambda_, test_set, max_iters, gamma, initial_w):\n",
    "    name = 'Logistic regression regularized'\n",
    "    \n",
    "    #w,loss = logistic_regression(y, tx, initial_w, max_iters, gamma)\n",
    "    w,loss = reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma)\n",
    "    \n",
    "    loss=loss/len(y);\n",
    "    y_pred = predict_labels(w, test_set)\n",
    "    create_csv_submission(ids_test, y_pred, OUT_FOLDER+name)\n",
    "    \n",
    "    plt.plot(w, 'go')\n",
    "    plt.title('logistic reg: weights with the normalized log-like:  '+str(loss),fontsize=15, fontweight='bold');\n",
    "    plt.show()\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAEKCAYAAAAYbfHYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWcHJkZmZmVnByZGZmZlZ4f8DU7Int3ZCWhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7cbf1e1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w, loss = func_logistic_reg (y=y_train, tx=tx_train, lambda_=lambda_best, test_set=tx_test, max_iters=50,\\\n",
    "                         gamma=gamma_best, initial_w=initial_w);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.364399999999989"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = predict_labels(w, tx_train)\n",
    "right_train = np.sum(y_pred_train == y_train)/len(y_train)*100\n",
    "right_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
