{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Functions tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessing_functions import *\n",
    "%matplotlib inline \n",
    "import numpy as np   # generic stuff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### REMOVE THIS LINE BEFORE SUBMISSION\n",
    "import pandas as pd\n",
    "#######################################################################\n",
    "\n",
    "from lib.helpers import * #the helper provided for the project\n",
    "# choose which implementations you would like\n",
    "from lib.implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/' \n",
    "\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_FOLDER+'train.csv',sub_sample=False)\n",
    "size_train = int(3*len(y_train)/4)\n",
    "y_test = y_train[:size_train]\n",
    "tx_test = tx_train[:size_train,:]\n",
    "ids_test = ids_train[:size_train]\n",
    "\n",
    "y_train = y_train[size_train:]\n",
    "tx_train = tx_train[size_train:,:]\n",
    "ids_train = ids_train[size_train:]\n",
    "\n",
    "#y_test, tx_test, ids_test = load_csv_data(DATA_FOLDER+'test.csv',sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"Build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_one_fold_LS(y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                 degrees, len_kept_data, stdize=False):\n",
    "    \n",
    "    accuracies_train_by_deg = np.zeros(len(degrees))\n",
    "    accuracies_test_by_deg = np.zeros(len(degrees))\n",
    "    \n",
    "    # For each degree, compute the least squares weights, the predictions and the accuracies\n",
    "    previous_deg = 1\n",
    "    for deg_id, deg in enumerate(degrees):\n",
    "        print('++ Degree', deg, '++')\n",
    "        \n",
    "        # Add powers of the chosen columns\n",
    "        len_data = tx_cross_val_train.shape[1]\n",
    "        tx_cross_val_train = add_powers(tx_cross_val_train, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        tx_cross_val_test = add_powers(tx_cross_val_test, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        if stdize: \n",
    "            tx_cross_val_train[:,len_data:] = standardize(tx_cross_val_train[:,len_data:])[0]\n",
    "            tx_cross_val_test[:,len_data:] = standardize(tx_cross_val_test[:,len_data:])[0]\n",
    "    \n",
    "        # Compute the best weights on the training set\n",
    "        weights, loss = least_squares(y_cross_val_train, tx_cross_val_train, 'mse') \n",
    "\n",
    "        # Compute the predictions\n",
    "        y_predicted_cross_val_train = predict_labels(weights, tx_cross_val_train)\n",
    "        y_predicted_cross_val_test = predict_labels(weights, tx_cross_val_test)\n",
    "\n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_deg[deg_id] = \\\n",
    "            np.sum(y_predicted_cross_val_train == y_cross_val_train)/len(y_cross_val_train)\n",
    "        accuracies_test_by_deg[deg_id] = \\\n",
    "            np.sum(y_predicted_cross_val_test == y_cross_val_test)/len(y_cross_val_test)\n",
    "        \n",
    "        # Update the previous degree to the actual degree\n",
    "        previous_deg = deg\n",
    "        \n",
    "    return accuracies_train_by_deg, accuracies_test_by_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_least_squares(y_single_jet_train, tx_single_jet_train, degrees, k_fold, seed):\n",
    "    \n",
    "    # Get the indices so that we get the k'th subgroup in test, others in train, for each k\n",
    "    k_indices = build_k_indices(y_single_jet_train, k_fold, seed)\n",
    "    \n",
    "    # Initialize matrix of computed accuracies for each degree and each fold\n",
    "    accuracies_train_by_fold = np.zeros([len(degrees), k_fold])\n",
    "    accuracies_test_by_fold = np.zeros([len(degrees), k_fold])\n",
    "    \n",
    "    # Preprocess training dataset\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'none')\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('--- Fold', k, '---')\n",
    "        # Create the testing set for this fold number\n",
    "        k_index = k_indices[k] # Indices of the testing set for fold k\n",
    "        y_cross_val_test = y_single_jet_train[k_index]\n",
    "        tx_cross_val_test = tx_single_jet_train_preprocessed[k_index,:]\n",
    "        \n",
    "        # Create the training set for this fold number\n",
    "        mask = np.ones(len(y_single_jet_train), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False # set test elements to False\n",
    "        y_cross_val_train = y_single_jet_train[mask] # select only True elements (ie train elements)\n",
    "        tx_cross_val_train = tx_single_jet_train_preprocessed[mask,:]\n",
    "        \n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_fold[:,k], accuracies_test_by_fold[:,k] = cross_validation_one_fold_LS\\\n",
    "            (y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, degrees, len_kept_data, \\\n",
    "             False)\n",
    "    \n",
    "    # Compute the mean accuracies over the folds, for each degree\n",
    "    mean_accuracies_train_by_deg = np.mean(accuracies_train_by_fold, axis=1)\n",
    "    mean_accuracies_test_by_deg = np.mean(accuracies_test_by_fold, axis=1)\n",
    "    \n",
    "    # Get the index of the best accuracy in the testing set\n",
    "    max_id_deg_test = np.unravel_index(mean_accuracies_test_by_deg.argmax(), mean_accuracies_test_by_deg.shape)\n",
    "    \n",
    "    # Find the optimal degree and the corresponding accuracies in the training and testing sets\n",
    "    best_deg = degrees[max_id_deg_test[0]]\n",
    "    best_accuracy_test = mean_accuracies_test_by_deg[max_id_deg_test[0]]\n",
    "    corresponding_accuracy_train = mean_accuracies_train_by_deg[max_id_deg_test[0]]\n",
    "    \n",
    "    print('Best accuracy test =', best_accuracy_test, 'with degree =', best_deg)\n",
    "    print('Corresponding accuracy train =', corresponding_accuracy_train)\n",
    "    \n",
    "    return best_deg, best_accuracy_test, corresponding_accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = range(6,11)\n",
    "k_fold = 5\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_jets_train = split_jets_mask(tx_train)\n",
    "mask_jets_test = split_jets_mask(tx_test)\n",
    "len_mask = len(mask_jets_train)\n",
    "\n",
    "y_predicted_train = np.zeros(len(y_train))\n",
    "y_predicted_test = np.zeros(tx_test.shape[0])\n",
    "best_degrees = np.zeros(len_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jet_id in range(len_mask):\n",
    "    print('***** Jet ', jet_id, '*****')\n",
    "    # SEPARATE THE WHOLE DATA SET TO GET ONLY THE PART THAT HAVE THE RIGHT NUMBER OF JETS\n",
    "    tx_single_jet_train = tx_train[mask_jets_train[jet_id]]\n",
    "    tx_single_jet_test = tx_test[mask_jets_test[jet_id]]\n",
    "    y_single_jet_train = y_train[mask_jets_train[jet_id]]\n",
    "    \n",
    "    # CALL CROSS VALIDATION FOR A SINGLE JET ON TRAIN PART, FIND BEST DEG, BEST ACCURACY ON TESTING CROSS VAL\n",
    "    best_deg, best_accuracy, corresponding_accuracy_train = cross_validation_least_squares(y_single_jet_train, \\\n",
    "                                                                                           tx_single_jet_train, \\\n",
    "                                                                                           degrees, k_fold, seed)\n",
    "    \n",
    "    # KEEP IN MEMORY THE BEST DEGREE FOR THIS JET\n",
    "    best_degrees[jet_id] = best_deg\n",
    "    \n",
    "    # PREPROCESS FULL TRAINING AND TESTING DATA\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'none')\n",
    "    tx_single_jet_test_preprocessed = preprocess_data(tx_single_jet_test, unique_cols, 'none')[0]\n",
    "    \n",
    "    # ADD POWERS TO THE CHOSEN COLUMNS\n",
    "    tx_single_jet_train_preprocessed = add_powers(tx_single_jet_train_preprocessed, range(2,best_deg+1), \\\n",
    "                                                  range(len_kept_data))\n",
    "    tx_single_jet_test_preprocessed = add_powers(tx_single_jet_test_preprocessed, range(2,best_deg+1), \\\n",
    "                                                 range(len_kept_data))\n",
    "    \n",
    "    # COMPUTE THE BEST WEIGHTS AND FULL ACCURACY ON TRAINING FULL SET - ONE JET\n",
    "    weights, loss = least_squares(y_single_jet_train, tx_single_jet_train_preprocessed, 'mse')\n",
    "    \n",
    "    # COMPUTE THE PREDICTIONS ON THE FULL TESTING SET - SINGLE JET\n",
    "    y_predicted_single_jet_train = predict_labels(weights, tx_single_jet_train_preprocessed)\n",
    "    y_predicted_single_jet_test = predict_labels(weights, tx_single_jet_test_preprocessed)\n",
    "    \n",
    "    # ADD THE PREDICTIONS TO y_predicted_test AND y_predicted_train\n",
    "    y_predicted_train[mask_jets_train[jet_id]] = y_predicted_single_jet_train\n",
    "    y_predicted_test[mask_jets_test[jet_id]] = y_predicted_single_jet_test\n",
    "    \n",
    "    # COMPUTE THE ACCURACY train ON JET\n",
    "    accuracy_train_single_jet = np.sum(y_predicted_single_jet_train == y_single_jet_train)/len(y_single_jet_train)\n",
    "    \n",
    "    # PRINT ACCURACY train ON JET\n",
    "    print('Accuracy full train on jet', jet_id, '=', accuracy_train_single_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CSV SUBMISSION\n",
    "#create_csv_submission(ids_test, y_predicted_test, 'output/trial.csv')\n",
    "\n",
    "# COMPUTE ACCURACY ON FULL train\n",
    "total_accuracy_train = np.sum(y_predicted_train == y_train)/len(y_train)*100\n",
    "print('Total accuracy train =', total_accuracy_train, 'with degrees =', best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy_test = np.sum(y_predicted_test == y_test)/len(y_test)*100\n",
    "print('Total accuracy test =', total_accuracy_test, 'with degrees =', best_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_one_fold_GD(y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                 degrees, gammas, len_kept_data, max_iters, stdize=False):\n",
    "    \n",
    "    accuracies_train_by_deg = np.zeros([len(degrees), len(gammas)])\n",
    "    accuracies_test_by_deg = np.zeros([len(degrees), len(gammas)])\n",
    "    \n",
    "    # For each degree, compute the least squares weights, the predictions and the accuracies\n",
    "    previous_deg = 1\n",
    "    for deg_id, deg in enumerate(degrees):\n",
    "        print('++ Degree', deg, '++')\n",
    "                \n",
    "        # Add powers of the chosen columns\n",
    "        len_data = tx_cross_val_train.shape[1]\n",
    "        tx_cross_val_train = add_powers(tx_cross_val_train, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        tx_cross_val_test = add_powers(tx_cross_val_test, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        if stdize: \n",
    "            tx_cross_val_train[:,len_data:] = standardize(tx_cross_val_train[:,len_data:])[0]\n",
    "            tx_cross_val_test[:,len_data:] = standardize(tx_cross_val_test[:,len_data:])[0]\n",
    "                \n",
    "        for gamma_id, single_gamma in enumerate(gammas):\n",
    "            print('>> Gamma', single_gamma, '<<')\n",
    "            \n",
    "            # Compute the best weights on the training set\n",
    "            initial_w = np.zeros(tx_cross_val_train.shape[1])\n",
    "            weights, loss = least_squares_GD(y_cross_val_train, tx_cross_val_train, initial_w, max_iters, \\\n",
    "                                             single_gamma, fct='mse');\n",
    "\n",
    "            # Compute the predictions\n",
    "            y_predicted_cross_val_train = predict_labels(weights, tx_cross_val_train)\n",
    "            y_predicted_cross_val_test = predict_labels(weights, tx_cross_val_test)\n",
    "\n",
    "            # Compute the accuracies for each degree\n",
    "            accuracies_train_by_deg[deg_id, gamma_id] = \\\n",
    "                np.sum(y_predicted_cross_val_train == y_cross_val_train)/len(y_cross_val_train)\n",
    "            accuracies_test_by_deg[deg_id, gamma_id] = \\\n",
    "                np.sum(y_predicted_cross_val_test == y_cross_val_test)/len(y_cross_val_test)\n",
    "\n",
    "        # Update the previous degree to the actual degree\n",
    "        previous_deg = deg\n",
    "        \n",
    "    return accuracies_train_by_deg, accuracies_test_by_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_GD(y_single_jet_train, tx_single_jet_train, degrees, gammas, k_fold, seed, max_iters):\n",
    "    \n",
    "    # Get the indices so that we get the k'th subgroup in test, others in train, for each k\n",
    "    k_indices = build_k_indices(y_single_jet_train, k_fold, seed)\n",
    "    \n",
    "    # Initialize matrix of computed accuracies for each degree and each fold\n",
    "    accuracies_train_by_fold = np.zeros([len(degrees), len(gammas), k_fold])\n",
    "    accuracies_test_by_fold = np.zeros([len(degrees), len(gammas), k_fold])\n",
    "    \n",
    "    # Preprocess training dataset\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'after')\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('--- Fold', k, '---')\n",
    "        # Create the testing set for this fold number\n",
    "        k_index = k_indices[k] # Indices of the testing set for fold k\n",
    "        y_cross_val_test = y_single_jet_train[k_index]\n",
    "        tx_cross_val_test = tx_single_jet_train_preprocessed[k_index,:]\n",
    "        \n",
    "        # Create the training set for this fold number\n",
    "        mask = np.ones(len(y_single_jet_train), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False # set test elements to False\n",
    "        y_cross_val_train = y_single_jet_train[mask] # select only True elements (ie train elements)\n",
    "        tx_cross_val_train = tx_single_jet_train_preprocessed[mask,:]\n",
    "        \n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_fold[:,:,k], accuracies_test_by_fold[:,:,k] = cross_validation_one_fold_GD\\\n",
    "            (y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                 degrees, gammas, len_kept_data, max_iters, True)\n",
    "    \n",
    "    # Compute the mean accuracies over the folds, for each degree\n",
    "    mean_accuracies_train_by_deg = np.mean(accuracies_train_by_fold, axis=2)\n",
    "    mean_accuracies_test_by_deg = np.mean(accuracies_test_by_fold, axis=2)\n",
    "    \n",
    "    # Get the index of the best accuracy in the testing set\n",
    "    max_id_deg_test, max_id_gamma_test = \\\n",
    "        np.unravel_index(mean_accuracies_test_by_deg.argmax(), mean_accuracies_test_by_deg.shape)\n",
    "    \n",
    "    # Find the optimal degree and the corresponding accuracies in the training and testing sets\n",
    "    best_deg = degrees[max_id_deg_test]\n",
    "    best_gamma = gammas[max_id_gamma_test]\n",
    "    best_accuracy_test = mean_accuracies_test_by_deg[max_id_deg_test, max_id_gamma_test]\n",
    "    corresponding_accuracy_train = mean_accuracies_train_by_deg[max_id_deg_test, max_id_gamma_test]\n",
    "    \n",
    "    print('Best accuracy test =', best_accuracy_test, 'with degree =', best_deg, 'and gamma =', best_gamma)\n",
    "    print('Corresponding accuracy train =', corresponding_accuracy_train)\n",
    "    \n",
    "    return best_deg, best_gamma, best_accuracy_test, corresponding_accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = range(6,11)\n",
    "gammas = np.logspace(-5,-1,5)\n",
    "k_fold = 5\n",
    "seed = 1\n",
    "max_iters = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_jets_train = split_jets_mask(tx_train)\n",
    "mask_jets_test = split_jets_mask(tx_test)\n",
    "len_mask = len(mask_jets_train)\n",
    "\n",
    "y_predicted_train = np.zeros(len(y_train))\n",
    "y_predicted_test = np.zeros(tx_test.shape[0])\n",
    "best_degrees = np.zeros(len_mask)\n",
    "best_gammas = np.zeros(len_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jet_id in range(len_mask):\n",
    "    print('***** Jet ', jet_id, '*****')\n",
    "    # SEPARATE THE WHOLE DATA SET TO GET ONLY THE PART THAT HAVE THE RIGHT NUMBER OF JETS\n",
    "    tx_single_jet_train = tx_train[mask_jets_train[jet_id]]\n",
    "    tx_single_jet_test = tx_test[mask_jets_test[jet_id]]\n",
    "    y_single_jet_train = y_train[mask_jets_train[jet_id]]\n",
    "    \n",
    "    # CALL CROSS VALIDATION FOR A SINGLE JET ON TRAIN PART, FIND BEST DEG, BEST ACCURACY ON TESTING CROSS VAL\n",
    "    best_deg, best_gamma, best_accuracy_test, corresponding_accuracy_train = \\\n",
    "        cross_validation_GD(y_single_jet_train, tx_single_jet_train, degrees, gammas, k_fold, seed, max_iters)\n",
    "    \n",
    "    # KEEP IN MEMORY THE BEST DEGREE FOR THIS JET\n",
    "    best_degrees[jet_id] = best_deg\n",
    "    best_gammas[jet_id] = best_gamma\n",
    "    \n",
    "    # PREPROCESS FULL TRAINING AND TESTING DATA\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'after')\n",
    "    tx_single_jet_test_preprocessed = preprocess_data(tx_single_jet_test, unique_cols, 'after')[0]\n",
    "    \n",
    "    # ADD POWERS TO THE CHOSEN COLUMNS\n",
    "    len_data = tx_single_jet_train_preprocessed.shape[1]\n",
    "    tx_single_jet_train_preprocessed = add_powers(tx_single_jet_train_preprocessed, range(2,best_deg+1), \\\n",
    "                                                  range(len_kept_data))\n",
    "    tx_single_jet_test_preprocessed = add_powers(tx_single_jet_test_preprocessed, range(2,best_deg+1), \\\n",
    "                                                 range(len_kept_data))\n",
    "    tx_single_jet_train_preprocessed[:,len_data:] = standardize(tx_single_jet_train_preprocessed[:,len_data:])[0]\n",
    "    tx_single_jet_test_preprocessed[:,len_data:] = standardize(tx_single_jet_test_preprocessed[:,len_data:])[0]\n",
    "    \n",
    "    # COMPUTE THE BEST WEIGHTS AND FULL ACCURACY ON TRAINING FULL SET - ONE JET\n",
    "    initial_w = np.zeros(tx_single_jet_train_preprocessed.shape[1])\n",
    "    weights, loss = least_squares_GD(y_single_jet_train, tx_single_jet_train_preprocessed, initial_w, max_iters, \\\n",
    "                                             best_gamma, fct='mse');\n",
    "    \n",
    "    # COMPUTE THE PREDICTIONS ON THE FULL TESTING SET - SINGLE JET\n",
    "    y_predicted_single_jet_train = predict_labels(weights, tx_single_jet_train_preprocessed)\n",
    "    y_predicted_single_jet_test = predict_labels(weights, tx_single_jet_test_preprocessed)\n",
    "    \n",
    "    # ADD THE PREDICTIONS TO y_predicted_test AND y_predicted_train\n",
    "    y_predicted_train[mask_jets_train[jet_id]] = y_predicted_single_jet_train\n",
    "    y_predicted_test[mask_jets_test[jet_id]] = y_predicted_single_jet_test\n",
    "    \n",
    "    # COMPUTE THE ACCURACY train ON JET\n",
    "    accuracy_train_single_jet = np.sum(y_predicted_single_jet_train == y_single_jet_train)/len(y_single_jet_train)\n",
    "    \n",
    "    # PRINT ACCURACY train ON JET\n",
    "    print('Accuracy full train on jet', jet_id, '=', accuracy_train_single_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE CSV SUBMISSION\n",
    "#create_csv_submission(ids_test, y_predicted_test, 'output/trial.csv')\n",
    "\n",
    "# COMPUTE ACCURACY ON FULL train\n",
    "total_accuracy_train = np.sum(y_predicted_train == y_train)/len(y_train)*100\n",
    "print('Total accuracy train =', total_accuracy_train, 'with degrees =', best_degrees, 'and gammas =', best_gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_accuracy_test = np.sum(y_predicted_test == y_test)/len(y_test)*100\n",
    "print('Total accuracy test =', total_accuracy_test, 'with degrees =', best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_test[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_one_fold_ridge(y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                    degrees, lambdas, len_kept_data, stdize=False):\n",
    "    \n",
    "    accuracies_train_by_deg = np.zeros([len(degrees), len(lambdas)])\n",
    "    accuracies_test_by_deg = np.zeros([len(degrees), len(lambdas)])\n",
    "    \n",
    "    # For each degree, compute the least squares weights, the predictions and the accuracies\n",
    "    previous_deg = 1\n",
    "    for deg_id, deg in enumerate(degrees):\n",
    "        print('++ Degree', deg, '++')\n",
    "                \n",
    "        # Add powers of the chosen columns\n",
    "        len_data = tx_cross_val_train.shape[1]\n",
    "        tx_cross_val_train = add_powers(tx_cross_val_train, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        tx_cross_val_test = add_powers(tx_cross_val_test, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        if stdize: \n",
    "            tx_cross_val_train[:,len_data:] = standardize(tx_cross_val_train[:,len_data:])[0]\n",
    "            tx_cross_val_test[:,len_data:] = standardize(tx_cross_val_test[:,len_data:])[0]\n",
    "                \n",
    "        for lambda_id, single_lambda in enumerate(lambdas):\n",
    "            print('>> Lambda', single_lambda, '<<')\n",
    "            \n",
    "            # Compute the best weights on the training set\n",
    "            weights, loss = ridge_regression(y_cross_val_train, tx_cross_val_train, single_lambda, 'mse');\n",
    "\n",
    "            # Compute the predictions\n",
    "            y_predicted_cross_val_train = predict_labels(weights, tx_cross_val_train)\n",
    "            y_predicted_cross_val_test = predict_labels(weights, tx_cross_val_test)\n",
    "\n",
    "            # Compute the accuracies for each degree\n",
    "            accuracies_train_by_deg[deg_id, lambda_id] = \\\n",
    "                np.sum(y_predicted_cross_val_train == y_cross_val_train)/len(y_cross_val_train)\n",
    "            accuracies_test_by_deg[deg_id, lambda_id] = \\\n",
    "                np.sum(y_predicted_cross_val_test == y_cross_val_test)/len(y_cross_val_test)\n",
    "\n",
    "        # Update the previous degree to the actual degree\n",
    "        previous_deg = deg\n",
    "        \n",
    "    return accuracies_train_by_deg, accuracies_test_by_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_ridge(y_single_jet_train, tx_single_jet_train, degrees, lambdas, k_fold, seed):\n",
    "    \n",
    "    # Get the indices so that we get the k'th subgroup in test, others in train, for each k\n",
    "    k_indices = build_k_indices(y_single_jet_train, k_fold, seed)\n",
    "    \n",
    "    # Initialize matrix of computed accuracies for each degree and each fold\n",
    "    accuracies_train_by_fold = np.zeros([len(degrees), len(lambdas), k_fold])\n",
    "    accuracies_test_by_fold = np.zeros([len(degrees), len(lambdas), k_fold])\n",
    "    \n",
    "    # Preprocess training dataset\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'before')\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('--- Fold', k, '---')\n",
    "        # Create the testing set for this fold number\n",
    "        k_index = k_indices[k] # Indices of the testing set for fold k\n",
    "        y_cross_val_test = y_single_jet_train[k_index]\n",
    "        tx_cross_val_test = tx_single_jet_train_preprocessed[k_index,:]\n",
    "        \n",
    "        # Create the training set for this fold number\n",
    "        mask = np.ones(len(y_single_jet_train), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False # set test elements to False\n",
    "        y_cross_val_train = y_single_jet_train[mask] # select only True elements (ie train elements)\n",
    "        tx_cross_val_train = tx_single_jet_train_preprocessed[mask,:]\n",
    "        \n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_fold[:,:,k], accuracies_test_by_fold[:,:,k] = \\\n",
    "            cross_validation_one_fold_ridge(y_cross_val_train, y_cross_val_test, tx_cross_val_train, \\\n",
    "                                            tx_cross_val_test, degrees, lambdas, len_kept_data, False)\n",
    "    \n",
    "    # Compute the mean accuracies over the folds, for each degree\n",
    "    mean_accuracies_train_by_deg = np.mean(accuracies_train_by_fold, axis=2)\n",
    "    mean_accuracies_test_by_deg = np.mean(accuracies_test_by_fold, axis=2)\n",
    "    \n",
    "    # Get the index of the best accuracy in the testing set\n",
    "    max_id_deg_test, max_id_lambda_test = \\\n",
    "        np.unravel_index(mean_accuracies_test_by_deg.argmax(), mean_accuracies_test_by_deg.shape)\n",
    "    \n",
    "    # Find the optimal degree and the corresponding accuracies in the training and testing sets\n",
    "    best_deg = degrees[max_id_deg_test]\n",
    "    best_lambda = lambdas[max_id_lambda_test]\n",
    "    best_accuracy_test = mean_accuracies_test_by_deg[max_id_deg_test, max_id_lambda_test]\n",
    "    corresponding_accuracy_train = mean_accuracies_train_by_deg[max_id_deg_test, max_id_lambda_test]\n",
    "    \n",
    "    print('Best accuracy test =', best_accuracy_test, 'with degree =', best_deg, 'and lambda =', best_lambda)\n",
    "    print('Corresponding accuracy train =', corresponding_accuracy_train)\n",
    "    \n",
    "    return best_deg, best_lambda, best_accuracy_test, corresponding_accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = range(6,11)\n",
    "lambdas = np.logspace(-9,-2,7)\n",
    "k_fold = 5\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_jets_train = split_jets_mask(tx_train)\n",
    "mask_jets_test = split_jets_mask(tx_test)\n",
    "len_mask = len(mask_jets_train)\n",
    "\n",
    "y_predicted_train = np.zeros(len(y_train))\n",
    "y_predicted_test = np.zeros(tx_test.shape[0])\n",
    "best_degrees = np.zeros(len_mask)\n",
    "best_lambdas = np.zeros(len_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jet_id in range(len_mask):\n",
    "    print('***** Jet ', jet_id, '*****')\n",
    "    # SEPARATE THE WHOLE DATA SET TO GET ONLY THE PART THAT HAVE THE RIGHT NUMBER OF JETS\n",
    "    tx_single_jet_train = tx_train[mask_jets_train[jet_id]]\n",
    "    tx_single_jet_test = tx_test[mask_jets_test[jet_id]]\n",
    "    y_single_jet_train = y_train[mask_jets_train[jet_id]]\n",
    "    \n",
    "    # CALL CROSS VALIDATION FOR A SINGLE JET ON TRAIN PART, FIND BEST DEG, BEST ACCURACY ON TESTING CROSS VAL\n",
    "    best_deg, best_lambda, best_accuracy_test, corresponding_accuracy_train = \\\n",
    "        cross_validation_ridge(y_single_jet_train, tx_single_jet_train, degrees, lambdas, k_fold, seed)\n",
    "    \n",
    "    # KEEP IN MEMORY THE BEST DEGREE FOR THIS JET\n",
    "    best_degrees[jet_id] = best_deg\n",
    "    best_lambdas[jet_id] = best_lambda\n",
    "    \n",
    "    # PREPROCESS FULL TRAINING AND TESTING DATA\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'before')\n",
    "    tx_single_jet_test_preprocessed = preprocess_data(tx_single_jet_test, unique_cols, 'before')[0]\n",
    "    \n",
    "    # ADD POWERS TO THE CHOSEN COLUMNS\n",
    "    len_data = tx_single_jet_train_preprocessed.shape[1]\n",
    "    tx_single_jet_train_preprocessed = add_powers(tx_single_jet_train_preprocessed, range(2,best_deg+1), \\\n",
    "                                                  range(len_kept_data))\n",
    "    tx_single_jet_test_preprocessed = add_powers(tx_single_jet_test_preprocessed, range(2,best_deg+1), \\\n",
    "                                                 range(len_kept_data))\n",
    "    tx_single_jet_train_preprocessed[:,len_data:] = standardize(tx_single_jet_train_preprocessed[:,len_data:])[0]\n",
    "    tx_single_jet_test_preprocessed[:,len_data:] = standardize(tx_single_jet_test_preprocessed[:,len_data:])[0]\n",
    "    \n",
    "    # COMPUTE THE BEST WEIGHTS AND FULL ACCURACY ON TRAINING FULL SET - ONE JET\n",
    "    initial_w = np.zeros(tx_single_jet_train_preprocessed.shape[1])\n",
    "    weights, loss = ridge_regression(y_single_jet_train, tx_single_jet_train_preprocessed, \\\n",
    "                                             best_lambda, fct='mse');\n",
    "    \n",
    "    # COMPUTE THE PREDICTIONS ON THE FULL TESTING SET - SINGLE JET\n",
    "    y_predicted_single_jet_train = predict_labels(weights, tx_single_jet_train_preprocessed)\n",
    "    y_predicted_single_jet_test = predict_labels(weights, tx_single_jet_test_preprocessed)\n",
    "    \n",
    "    # ADD THE PREDICTIONS TO y_predicted_test AND y_predicted_train\n",
    "    y_predicted_train[mask_jets_train[jet_id]] = y_predicted_single_jet_train\n",
    "    y_predicted_test[mask_jets_test[jet_id]] = y_predicted_single_jet_test\n",
    "    \n",
    "    # COMPUTE THE ACCURACY train ON JET\n",
    "    accuracy_train_single_jet = np.sum(y_predicted_single_jet_train == y_single_jet_train)/len(y_single_jet_train)\n",
    "    \n",
    "    # PRINT ACCURACY train ON JET\n",
    "    print('Accuracy full train on jet', jet_id, '=', accuracy_train_single_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CSV SUBMISSION\n",
    "#create_csv_submission(ids_test, y_predicted_test, 'output/trial.csv')\n",
    "\n",
    "# COMPUTE ACCURACY ON FULL train\n",
    "total_accuracy_train = np.sum(y_predicted_train == y_train)/len(y_train)*100\n",
    "print('Total accuracy train =', total_accuracy_train, 'with degrees =', best_degrees, 'and lambda =', best_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy_test = np.sum(y_predicted_test == y_test)/len(y_test)*100\n",
    "print('Total accuracy test =', total_accuracy_test, 'with degrees =', best_degrees, 'and lambda =', best_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_one_fold_SGD(y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                 degrees, gammas, len_kept_data, max_iters, batch_size, stdize=False):\n",
    "    \n",
    "    accuracies_train_by_deg = np.zeros([len(degrees), len(gammas)])\n",
    "    accuracies_test_by_deg = np.zeros([len(degrees), len(gammas)])\n",
    "    \n",
    "    # For each degree, compute the least squares weights, the predictions and the accuracies\n",
    "    previous_deg = 1\n",
    "    for deg_id, deg in enumerate(degrees):\n",
    "        print('++ Degree', deg, '++')\n",
    "                \n",
    "        # Add powers of the chosen columns\n",
    "        len_data = tx_cross_val_train.shape[1]\n",
    "        tx_cross_val_train = add_powers(tx_cross_val_train, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        tx_cross_val_test = add_powers(tx_cross_val_test, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        if stdize: \n",
    "            tx_cross_val_train[:,len_data:] = standardize(tx_cross_val_train[:,len_data:])[0]\n",
    "            tx_cross_val_test[:,len_data:] = standardize(tx_cross_val_test[:,len_data:])[0]\n",
    "                \n",
    "        for gamma_id, single_gamma in enumerate(gammas):\n",
    "            print('>> Gamma', single_gamma, '<<')\n",
    "            \n",
    "            # Compute the best weights on the training set\n",
    "            initial_w = np.zeros(tx_cross_val_train.shape[1])\n",
    "            weights, loss = least_squares_SGD(y_cross_val_train, tx_cross_val_train, initial_w, max_iters, \\\n",
    "                                             single_gamma, batch_size);\n",
    "\n",
    "            # Compute the predictions\n",
    "            y_predicted_cross_val_train = predict_labels(weights, tx_cross_val_train)\n",
    "            y_predicted_cross_val_test = predict_labels(weights, tx_cross_val_test)\n",
    "\n",
    "            # Compute the accuracies for each degree\n",
    "            accuracies_train_by_deg[deg_id, gamma_id] = \\\n",
    "                np.sum(y_predicted_cross_val_train == y_cross_val_train)/len(y_cross_val_train)\n",
    "            accuracies_test_by_deg[deg_id, gamma_id] = \\\n",
    "                np.sum(y_predicted_cross_val_test == y_cross_val_test)/len(y_cross_val_test)\n",
    "\n",
    "        # Update the previous degree to the actual degree\n",
    "        previous_deg = deg\n",
    "        \n",
    "    return accuracies_train_by_deg, accuracies_test_by_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_SGD(y_single_jet_train, tx_single_jet_train, degrees, gammas, k_fold, seed, max_iters, \\\n",
    "                        batch_size):\n",
    "    \n",
    "    # Get the indices so that we get the k'th subgroup in test, others in train, for each k\n",
    "    k_indices = build_k_indices(y_single_jet_train, k_fold, seed)\n",
    "    \n",
    "    # Initialize matrix of computed accuracies for each degree and each fold\n",
    "    accuracies_train_by_fold = np.zeros([len(degrees), len(gammas), k_fold])\n",
    "    accuracies_test_by_fold = np.zeros([len(degrees), len(gammas), k_fold])\n",
    "    \n",
    "    # Preprocess training dataset\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'after')\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('--- Fold', k, '---')\n",
    "        # Create the testing set for this fold number\n",
    "        k_index = k_indices[k] # Indices of the testing set for fold k\n",
    "        y_cross_val_test = y_single_jet_train[k_index]\n",
    "        tx_cross_val_test = tx_single_jet_train_preprocessed[k_index,:]\n",
    "        \n",
    "        # Create the training set for this fold number\n",
    "        mask = np.ones(len(y_single_jet_train), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False # set test elements to False\n",
    "        y_cross_val_train = y_single_jet_train[mask] # select only True elements (ie train elements)\n",
    "        tx_cross_val_train = tx_single_jet_train_preprocessed[mask,:]\n",
    "        \n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_fold[:,:,k], accuracies_test_by_fold[:,:,k] = \\\n",
    "            cross_validation_one_fold_SGD(y_cross_val_train, y_cross_val_test, tx_cross_val_train, \\\n",
    "                                          tx_cross_val_test, degrees, gammas, len_kept_data, max_iters, \\\n",
    "                                          batch_size, True)\n",
    "    \n",
    "    # Compute the mean accuracies over the folds, for each degree\n",
    "    mean_accuracies_train_by_deg = np.mean(accuracies_train_by_fold, axis=2)\n",
    "    mean_accuracies_test_by_deg = np.mean(accuracies_test_by_fold, axis=2)\n",
    "    \n",
    "    # Get the index of the best accuracy in the testing set\n",
    "    max_id_deg_test, max_id_gamma_test = \\\n",
    "        np.unravel_index(mean_accuracies_test_by_deg.argmax(), mean_accuracies_test_by_deg.shape)\n",
    "    \n",
    "    # Find the optimal degree and the corresponding accuracies in the training and testing sets\n",
    "    best_deg = degrees[max_id_deg_test]\n",
    "    best_gamma = gammas[max_id_gamma_test]\n",
    "    best_accuracy_test = mean_accuracies_test_by_deg[max_id_deg_test, max_id_gamma_test]\n",
    "    corresponding_accuracy_train = mean_accuracies_train_by_deg[max_id_deg_test, max_id_gamma_test]\n",
    "    \n",
    "    print('Best accuracy test =', best_accuracy_test, 'with degree =', best_deg, 'and gamma =', best_gamma)\n",
    "    print('Corresponding accuracy train =', corresponding_accuracy_train)\n",
    "    \n",
    "    return best_deg, best_gamma, best_accuracy_test, corresponding_accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = range(3,10)\n",
    "gammas = np.logspace(-6,-1,5)\n",
    "k_fold = 5\n",
    "seed = 1\n",
    "max_iters = 300\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_jets_train = split_jets_mask(tx_train)\n",
    "mask_jets_test = split_jets_mask(tx_test)\n",
    "len_mask = len(mask_jets_train)\n",
    "\n",
    "y_predicted_train = np.zeros(len(y_train))\n",
    "y_predicted_test = np.zeros(tx_test.shape[0])\n",
    "best_degrees = np.zeros(len_mask)\n",
    "best_gammas = np.zeros(len_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jet_id in range(len_mask):\n",
    "    print('***** Jet ', jet_id, '*****')\n",
    "    # SEPARATE THE WHOLE DATA SET TO GET ONLY THE PART THAT HAVE THE RIGHT NUMBER OF JETS\n",
    "    tx_single_jet_train = tx_train[mask_jets_train[jet_id]]\n",
    "    tx_single_jet_test = tx_test[mask_jets_test[jet_id]]\n",
    "    y_single_jet_train = y_train[mask_jets_train[jet_id]]\n",
    "    \n",
    "    # CALL CROSS VALIDATION FOR A SINGLE JET ON TRAIN PART, FIND BEST DEG, BEST ACCURACY ON TESTING CROSS VAL\n",
    "    best_deg, best_gamma, best_accuracy_test, corresponding_accuracy_train = \\\n",
    "        cross_validation_SGD(y_single_jet_train, tx_single_jet_train, degrees, gammas, k_fold, seed, max_iters, \\\n",
    "                            batch_size)\n",
    "    \n",
    "    # KEEP IN MEMORY THE BEST DEGREE FOR THIS JET\n",
    "    best_degrees[jet_id] = best_deg\n",
    "    best_gammas[jet_id] = best_gamma\n",
    "    \n",
    "    # PREPROCESS FULL TRAINING AND TESTING DATA\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'after')\n",
    "    tx_single_jet_test_preprocessed = preprocess_data(tx_single_jet_test, unique_cols, 'after')[0]\n",
    "    \n",
    "    # ADD POWERS TO THE CHOSEN COLUMNS\n",
    "    len_data = tx_single_jet_train_preprocessed.shape[1]\n",
    "    tx_single_jet_train_preprocessed = add_powers(tx_single_jet_train_preprocessed, range(2,best_deg+1), \\\n",
    "                                                  range(len_kept_data))\n",
    "    tx_single_jet_test_preprocessed = add_powers(tx_single_jet_test_preprocessed, range(2,best_deg+1), \\\n",
    "                                                 range(len_kept_data))\n",
    "    tx_single_jet_train_preprocessed[:,len_data:] = standardize(tx_single_jet_train_preprocessed[:,len_data:])[0]\n",
    "    tx_single_jet_test_preprocessed[:,len_data:] = standardize(tx_single_jet_test_preprocessed[:,len_data:])[0]\n",
    "    \n",
    "    # COMPUTE THE BEST WEIGHTS AND FULL ACCURACY ON TRAINING FULL SET - ONE JET\n",
    "    initial_w = np.zeros(tx_single_jet_train_preprocessed.shape[1])\n",
    "    weights, loss = least_squares_SGD(y_single_jet_train, tx_single_jet_train_preprocessed, initial_w, max_iters, \\\n",
    "                                             best_gamma, batch_size);\n",
    "    \n",
    "    # COMPUTE THE PREDICTIONS ON THE FULL TESTING SET - SINGLE JET\n",
    "    y_predicted_single_jet_train = predict_labels(weights, tx_single_jet_train_preprocessed)\n",
    "    y_predicted_single_jet_test = predict_labels(weights, tx_single_jet_test_preprocessed)\n",
    "    \n",
    "    # ADD THE PREDICTIONS TO y_predicted_test AND y_predicted_train\n",
    "    y_predicted_train[mask_jets_train[jet_id]] = y_predicted_single_jet_train\n",
    "    y_predicted_test[mask_jets_test[jet_id]] = y_predicted_single_jet_test\n",
    "    \n",
    "    # COMPUTE THE ACCURACY train ON JET\n",
    "    accuracy_train_single_jet = np.sum(y_predicted_single_jet_train == y_single_jet_train)/len(y_single_jet_train)\n",
    "    \n",
    "    # PRINT ACCURACY train ON JET\n",
    "    print('Accuracy full train on jet', jet_id, '=', accuracy_train_single_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CSV SUBMISSION\n",
    "#create_csv_submission(ids_test, y_predicted_test, 'output/trial.csv')\n",
    "\n",
    "# COMPUTE ACCURACY ON FULL train\n",
    "total_accuracy_train = np.sum(y_predicted_train == y_train)/len(y_train)*100\n",
    "print('Total accuracy train =', total_accuracy_train, 'with degrees =', best_degrees, 'and gammas =', best_gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy_test = np.sum(y_predicted_test == y_test)/len(y_test)*100\n",
    "print('Total accuracy test =', total_accuracy_test, 'with degrees =', best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_one_fold_logreg(y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                    degrees, gammas, len_kept_data, max_iters, stdize=False):\n",
    "    \n",
    "    accuracies_train_by_deg = np.zeros([len(degrees), len(gammas)])\n",
    "    accuracies_test_by_deg = np.zeros([len(degrees), len(gammas)])\n",
    "    \n",
    "    # For each degree, compute the least squares weights, the predictions and the accuracies\n",
    "    previous_deg = 1\n",
    "    for deg_id, deg in enumerate(degrees):\n",
    "        print('++ Degree', deg, '++')\n",
    "                \n",
    "        # Add powers of the chosen columns\n",
    "        len_data = tx_cross_val_train.shape[1]\n",
    "        tx_cross_val_train = add_powers(tx_cross_val_train, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        tx_cross_val_test = add_powers(tx_cross_val_test, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        if stdize: \n",
    "            tx_cross_val_train[:,len_data:] = standardize(tx_cross_val_train[:,len_data:])[0]\n",
    "            tx_cross_val_test[:,len_data:] = standardize(tx_cross_val_test[:,len_data:])[0]\n",
    "                \n",
    "        for gamma_id, single_gamma in enumerate(gammas):\n",
    "            print('>> Gamma', single_gamma, '<<')\n",
    "            \n",
    "            # Compute the best weights on the training set\n",
    "            initial_w = np.zeros(tx_cross_val_train.shape[1])\n",
    "            weights, loss = logistic_regression(y_cross_val_train, tx_cross_val_train, initial_w, max_iters, \\\n",
    "                                                single_gamma);\n",
    "\n",
    "            # Compute the predictions\n",
    "            y_predicted_cross_val_train = predict_labels(weights, tx_cross_val_train)\n",
    "            y_predicted_cross_val_test = predict_labels(weights, tx_cross_val_test)\n",
    "\n",
    "            # Compute the accuracies for each degree\n",
    "            accuracies_train_by_deg[deg_id, gamma_id] = \\\n",
    "                np.sum(y_predicted_cross_val_train == y_cross_val_train)/len(y_cross_val_train)\n",
    "            accuracies_test_by_deg[deg_id, gamma_id] = \\\n",
    "                np.sum(y_predicted_cross_val_test == y_cross_val_test)/len(y_cross_val_test)\n",
    "\n",
    "        # Update the previous degree to the actual degree\n",
    "        previous_deg = deg\n",
    "        \n",
    "    return accuracies_train_by_deg, accuracies_test_by_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_logreg(y_single_jet_train, tx_single_jet_train, degrees, gammas, k_fold, seed, max_iters):\n",
    "    \n",
    "    # Get the indices so that we get the k'th subgroup in test, others in train, for each k\n",
    "    k_indices = build_k_indices(y_single_jet_train, k_fold, seed)\n",
    "    \n",
    "    # Initialize matrix of computed accuracies for each degree and each fold\n",
    "    accuracies_train_by_fold = np.zeros([len(degrees), len(gammas), k_fold])\n",
    "    accuracies_test_by_fold = np.zeros([len(degrees), len(gammas), k_fold])\n",
    "    \n",
    "    # Preprocess training dataset\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'before')\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('--- Fold', k, '---')\n",
    "        # Create the testing set for this fold number\n",
    "        k_index = k_indices[k] # Indices of the testing set for fold k\n",
    "        y_cross_val_test = y_single_jet_train[k_index]\n",
    "        tx_cross_val_test = tx_single_jet_train_preprocessed[k_index,:]\n",
    "        \n",
    "        # Create the training set for this fold number\n",
    "        mask = np.ones(len(y_single_jet_train), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False # set test elements to False\n",
    "        y_cross_val_train = y_single_jet_train[mask] # select only True elements (ie train elements)\n",
    "        tx_cross_val_train = tx_single_jet_train_preprocessed[mask,:]\n",
    "        \n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_fold[:,:,k], accuracies_test_by_fold[:,:,k] = \\\n",
    "            cross_validation_one_fold_logreg(y_cross_val_train, y_cross_val_test, tx_cross_val_train, \\\n",
    "                                            tx_cross_val_test, degrees, gammas, len_kept_data, max_iters, False)\n",
    "    \n",
    "    # Compute the mean accuracies over the folds, for each degree\n",
    "    mean_accuracies_train_by_deg = np.mean(accuracies_train_by_fold, axis=2)\n",
    "    mean_accuracies_test_by_deg = np.mean(accuracies_test_by_fold, axis=2)\n",
    "    \n",
    "    # Get the index of the best accuracy in the testing set\n",
    "    max_id_deg_test, max_id_gamma_test = \\\n",
    "        np.unravel_index(mean_accuracies_test_by_deg.argmax(), mean_accuracies_test_by_deg.shape)\n",
    "    \n",
    "    # Find the optimal degree and the corresponding accuracies in the training and testing sets\n",
    "    best_deg = degrees[max_id_deg_test]\n",
    "    best_gamma = gammas[max_id_gamma_test]\n",
    "    best_accuracy_test = mean_accuracies_test_by_deg[max_id_deg_test, max_id_gamma_test]\n",
    "    corresponding_accuracy_train = mean_accuracies_train_by_deg[max_id_deg_test, max_id_gamma_test]\n",
    "    \n",
    "    print('Best accuracy test =', best_accuracy_test, 'with degree =', best_deg, 'and gamma =', best_gamma)\n",
    "    print('Corresponding accuracy train =', corresponding_accuracy_train)\n",
    "    \n",
    "    return best_deg, best_gamma, best_accuracy_test, corresponding_accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = range(6,10)\n",
    "gammas = np.logspace(-9,-2,7)\n",
    "k_fold = 5\n",
    "seed = 1\n",
    "max_iters = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_jets_train = split_jets_mask(tx_train)\n",
    "mask_jets_test = split_jets_mask(tx_test)\n",
    "len_mask = len(mask_jets_train)\n",
    "\n",
    "y_predicted_train = np.zeros(len(y_train))\n",
    "y_predicted_test = np.zeros(tx_test.shape[0])\n",
    "best_degrees = np.zeros(len_mask)\n",
    "best_lambdas = np.zeros(len_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jet_id in range(len_mask):\n",
    "    print('***** Jet ', jet_id, '*****')\n",
    "    # SEPARATE THE WHOLE DATA SET TO GET ONLY THE PART THAT HAVE THE RIGHT NUMBER OF JETS\n",
    "    tx_single_jet_train = tx_train[mask_jets_train[jet_id]]\n",
    "    tx_single_jet_test = tx_test[mask_jets_test[jet_id]]\n",
    "    y_single_jet_train = y_train[mask_jets_train[jet_id]]\n",
    "    \n",
    "    # CALL CROSS VALIDATION FOR A SINGLE JET ON TRAIN PART, FIND BEST DEG, BEST ACCURACY ON TESTING CROSS VAL\n",
    "    best_deg, best_gamma, best_accuracy_test, corresponding_accuracy_train = \\\n",
    "        cross_validation_logreg(y_single_jet_train, tx_single_jet_train, degrees, gammas, k_fold, seed, max_iters)\n",
    "    \n",
    "    # KEEP IN MEMORY THE BEST DEGREE FOR THIS JET\n",
    "    best_degrees[jet_id] = best_deg\n",
    "    best_gammas[jet_id] = best_gamma\n",
    "    \n",
    "    # PREPROCESS FULL TRAINING AND TESTING DATA\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'before')\n",
    "    tx_single_jet_test_preprocessed = preprocess_data(tx_single_jet_test, unique_cols, 'before')[0]\n",
    "    \n",
    "    # ADD POWERS TO THE CHOSEN COLUMNS\n",
    "    len_data = tx_single_jet_train_preprocessed.shape[1]\n",
    "    tx_single_jet_train_preprocessed = add_powers(tx_single_jet_train_preprocessed, range(2,best_deg+1), \\\n",
    "                                                  range(len_kept_data))\n",
    "    tx_single_jet_test_preprocessed = add_powers(tx_single_jet_test_preprocessed, range(2,best_deg+1), \\\n",
    "                                                 range(len_kept_data))\n",
    "    tx_single_jet_train_preprocessed[:,len_data:] = standardize(tx_single_jet_train_preprocessed[:,len_data:])[0]\n",
    "    tx_single_jet_test_preprocessed[:,len_data:] = standardize(tx_single_jet_test_preprocessed[:,len_data:])[0]\n",
    "    \n",
    "    # COMPUTE THE BEST WEIGHTS AND FULL ACCURACY ON TRAINING FULL SET - ONE JET\n",
    "    initial_w = np.zeros(tx_single_jet_train_preprocessed.shape[1])\n",
    "    weights, loss = logistic_regression(y_single_jet_train, tx_single_jet_train_preprocessed, initial_w,\\\n",
    "                                        max_iters, best_gamma);\n",
    "    \n",
    "    # COMPUTE THE PREDICTIONS ON THE FULL TESTING SET - SINGLE JET\n",
    "    y_predicted_single_jet_train = predict_labels(weights, tx_single_jet_train_preprocessed)\n",
    "    y_predicted_single_jet_test = predict_labels(weights, tx_single_jet_test_preprocessed)\n",
    "    \n",
    "    # ADD THE PREDICTIONS TO y_predicted_test AND y_predicted_train\n",
    "    y_predicted_train[mask_jets_train[jet_id]] = y_predicted_single_jet_train\n",
    "    y_predicted_test[mask_jets_test[jet_id]] = y_predicted_single_jet_test\n",
    "    \n",
    "    # COMPUTE THE ACCURACY train ON JET\n",
    "    accuracy_train_single_jet = np.sum(y_predicted_single_jet_train == y_single_jet_train)/len(y_single_jet_train)\n",
    "    \n",
    "    # PRINT ACCURACY train ON JET\n",
    "    print('Accuracy full train on jet', jet_id, '=', accuracy_train_single_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CSV SUBMISSION\n",
    "#create_csv_submission(ids_test, y_predicted_test, 'output/trial.csv')\n",
    "\n",
    "# COMPUTE ACCURACY ON FULL train\n",
    "total_accuracy_train = np.sum(y_predicted_train == y_train)/len(y_train)*100\n",
    "print('Total accuracy train =', total_accuracy_train, 'with degrees =', best_degrees, 'and gamma =', best_gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy_test = np.sum(y_predicted_test == y_test)/len(y_test)*100\n",
    "print('Total accuracy test =', total_accuracy_test, 'with degrees =', best_degrees, 'and gamma =', best_gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGULARIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_one_fold_logistic_regularized(y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                 degrees, gammas, lambdas, len_kept_data, max_iters, stdize=False):\n",
    "    \n",
    "    accuracies_train_by_deg = np.zeros([len(degrees), len(gammas),len(lambdas)])\n",
    "    accuracies_test_by_deg = np.zeros([len(degrees), len(gammas),len(lambdas)])\n",
    "    \n",
    "    # For each degree, compute the least squares weights, the predictions and the accuracies\n",
    "    previous_deg = 1\n",
    "    for deg_id, deg in enumerate(degrees):\n",
    "        print('++ Degree', deg, '++')\n",
    "                \n",
    "        # Add powers of the chosen columns\n",
    "        len_data = tx_cross_val_train.shape[1]\n",
    "        tx_cross_val_train = add_powers(tx_cross_val_train, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        tx_cross_val_test = add_powers(tx_cross_val_test, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        if stdize: \n",
    "            tx_cross_val_train[:,len_data:] = standardize(tx_cross_val_train[:,len_data:])[0]\n",
    "            tx_cross_val_test[:,len_data:] = standardize(tx_cross_val_test[:,len_data:])[0]\n",
    "                \n",
    "        for gamma_id, single_gamma in enumerate(gammas):\n",
    "            print('>> Gamma', single_gamma, '<<')\n",
    "            \n",
    "            \n",
    "            for lambda_id, single_lambda in enumerate(lambdas):\n",
    "                \n",
    "                print('>> Lambda', single_lambda, '<<')\n",
    "            # Compute the best weights on the training set\n",
    "                initial_w = np.zeros(tx_cross_val_train.shape[1])\n",
    "                weights, loss = reg_logistic_regression(y_cross_val_train, tx_cross_val_train, single_lambda,initial_w, max_iters, \\\n",
    "                                                 single_gamma);\n",
    "\n",
    "                # Compute the predictions\n",
    "                y_predicted_cross_val_train = predict_labels(weights, tx_cross_val_train)\n",
    "                y_predicted_cross_val_test = predict_labels(weights, tx_cross_val_test)\n",
    "\n",
    "                # Compute the accuracies for each degree\n",
    "                accuracies_train_by_deg[deg_id, gamma_id,lambda_id] = \\\n",
    "                    np.sum(y_predicted_cross_val_train == y_cross_val_train)/len(y_cross_val_train)\n",
    "                accuracies_test_by_deg[deg_id, gamma_id,lambda_id] = \\\n",
    "                    np.sum(y_predicted_cross_val_test == y_cross_val_test)/len(y_cross_val_test)\n",
    "\n",
    "        # Update the previous degree to the actual degree\n",
    "        previous_deg = deg\n",
    "        \n",
    "    return accuracies_train_by_deg, accuracies_test_by_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_logistic_regularized(y_single_jet_train, tx_single_jet_train, degrees, gammas, lambdas, k_fold, seed, max_iters):\n",
    "    \n",
    "    # Get the indices so that we get the k'th subgroup in test, others in train, for each k\n",
    "    k_indices = build_k_indices(y_single_jet_train, k_fold, seed)\n",
    "    \n",
    "    # Initialize matrix of computed accuracies for each degree and each fold\n",
    "    accuracies_train_by_fold = np.zeros([len(degrees), len(gammas),len(lambdas), k_fold])\n",
    "    accuracies_test_by_fold = np.zeros([len(degrees), len(gammas),len(lambdas), k_fold])\n",
    "    \n",
    "    # Preprocess training dataset\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'after')\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('--- Fold', k, '---')\n",
    "        # Create the testing set for this fold number\n",
    "        k_index = k_indices[k] # Indices of the testing set for fold k\n",
    "        y_cross_val_test = y_single_jet_train[k_index]\n",
    "        tx_cross_val_test = tx_single_jet_train_preprocessed[k_index,:]\n",
    "        \n",
    "        # Create the training set for this fold number\n",
    "        mask = np.ones(len(y_single_jet_train), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False # set test elements to False\n",
    "        y_cross_val_train = y_single_jet_train[mask] # select only True elements (ie train elements)\n",
    "        tx_cross_val_train = tx_single_jet_train_preprocessed[mask,:]\n",
    "        \n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_fold[:,:,:,k], accuracies_test_by_fold[:,:,:,k] = cross_validation_one_fold_logistic_regularized\\\n",
    "            (y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                 degrees, gammas, lambdas, len_kept_data, max_iters, True)\n",
    "    \n",
    "    # Compute the mean accuracies over the folds, for each degree\n",
    "    mean_accuracies_train_by_deg = np.mean(accuracies_train_by_fold, axis=3)\n",
    "    mean_accuracies_test_by_deg = np.mean(accuracies_test_by_fold, axis=3)\n",
    "    \n",
    "    # Get the index of the best accuracy in the testing set\n",
    "    max_id_deg_test, max_id_gamma_test,max_id_lambda = \\\n",
    "        np.unravel_index(mean_accuracies_test_by_deg.argmax(), mean_accuracies_test_by_deg.shape)\n",
    "    \n",
    "    # Find the optimal degree and the corresponding accuracies in the training and testing sets\n",
    "    best_deg = degrees[max_id_deg_test]\n",
    "    best_gamma = gammas[max_id_gamma_test]\n",
    "    best_lambda=lambdas[max_id_lambda]\n",
    "    best_accuracy_test = mean_accuracies_test_by_deg[max_id_deg_test, max_id_gamma_test,max_id_lambda]\n",
    "    corresponding_accuracy_train = mean_accuracies_train_by_deg[max_id_deg_test, max_id_gamma_test,max_id_lambda]\n",
    "    \n",
    "    print('Best accuracy test =', best_accuracy_test, 'with degree =', best_deg)\n",
    "    print('Corresponding accuracy train =', corresponding_accuracy_train)\n",
    "    \n",
    "    return best_deg, best_gamma, best_lambda, best_accuracy_test, corresponding_accuracy_train                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = range(6,11)\n",
    "gammas = np.logspace(-8,-2,6)\n",
    "lambdas = np.logspace(-8,-2,6)\n",
    "\n",
    "k_fold = 5\n",
    "seed = 1\n",
    "max_iters = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_jets_train = split_jets_mask(tx_train)\n",
    "mask_jets_test = split_jets_mask(tx_test)\n",
    "len_mask = len(mask_jets_train)\n",
    "\n",
    "y_predicted_train = np.zeros(len(y_train))\n",
    "y_predicted_test = np.zeros(tx_test.shape[0])\n",
    "best_degrees = np.zeros(len_mask)\n",
    "best_gammas = np.zeros(len_mask)\n",
    "best_lambdas=np.zeros(len_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet_id in range(len_mask):\n",
    "    print('** Jet ', jet_id, '**')\n",
    "    # SEPARATE THE WHOLE DATA SET TO GET ONLY THE PART THAT HAVE THE RIGHT NUMBER OF JETS\n",
    "    tx_single_jet_train = tx_train[mask_jets_train[jet_id]]\n",
    "    tx_single_jet_test = tx_test[mask_jets_test[jet_id]]\n",
    "    y_single_jet_train = y_train[mask_jets_train[jet_id]]\n",
    "    \n",
    "    # CALL CROSS VALIDATION FOR A SINGLE JET ON TRAIN PART, FIND BEST DEG, BEST ACCURACY ON TESTING CROSS VAL\n",
    "    best_deg, best_gamma, best_lambda, best_accuracy_test, corresponding_accuracy_train = \\\n",
    "        cross_validation_logistic_regularized(y_single_jet_train, tx_single_jet_train, degrees, gammas, lambdas, k_fold, seed, max_iters)\n",
    "    \n",
    "    # KEEP IN MEMORY THE BEST DEGREE FOR THIS JET\n",
    "    best_degrees[jet_id] = best_deg\n",
    "    best_gammas[jet_id] = best_gamma\n",
    "    best_lambdas[jet_id]=best_lambda\n",
    "    # PREPROCESS FULL TRAINING AND TESTING DATA\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'after')\n",
    "    tx_single_jet_test_preprocessed = preprocess_data(tx_single_jet_test, unique_cols, 'after')[0]\n",
    "    \n",
    "    # ADD POWERS TO THE CHOSEN COLUMNS\n",
    "    len_data = tx_single_jet_train_preprocessed.shape[1]\n",
    "    tx_single_jet_train_preprocessed = add_powers(tx_single_jet_train_preprocessed, range(2,best_deg+1), \\\n",
    "                                                  range(len_kept_data))\n",
    "    tx_single_jet_test_preprocessed = add_powers(tx_single_jet_test_preprocessed, range(2,best_deg+1), \\\n",
    "                                                 range(len_kept_data))\n",
    "    tx_single_jet_train_preprocessed[:,len_data:] = standardize(tx_single_jet_train_preprocessed[:,len_data:])[0]\n",
    "    tx_single_jet_test_preprocessed[:,len_data:] = standardize(tx_single_jet_test_preprocessed[:,len_data:])[0]\n",
    "    \n",
    "    # COMPUTE THE BEST WEIGHTS AND FULL ACCURACY ON TRAINING FULL SET - ONE JET\n",
    "    initial_w = np.zeros(tx_single_jet_train_preprocessed.shape[1])\n",
    "    weights, loss = reg_logistic_regression(y_single_jet_train, tx_single_jet_train_preprocessed , best_lambda, initial_w, max_iters, best_gamma)\n",
    "    \n",
    "    # COMPUTE THE PREDICTIONS ON THE FULL TESTING SET - SINGLE JET\n",
    "    y_predicted_single_jet_train = predict_labels(weights, tx_single_jet_train_preprocessed)\n",
    "    y_predicted_single_jet_test = predict_labels(weights, tx_single_jet_test_preprocessed)\n",
    "    \n",
    "    # ADD THE PREDICTIONS TO y_predicted_test AND y_predicted_train\n",
    "    y_predicted_train[mask_jets_train[jet_id]] = y_predicted_single_jet_train\n",
    "    y_predicted_test[mask_jets_test[jet_id]] = y_predicted_single_jet_test\n",
    "    \n",
    "    # COMPUTE THE ACCURACY train ON JET\n",
    "    accuracy_train_single_jet = np.sum(y_predicted_single_jet_train == y_single_jet_train)/len(y_single_jet_train)\n",
    "    \n",
    "    # PRINT ACCURACY train ON JET\n",
    "    print('Accuracy full train on jet', jet_id, '=', accuracy_train_single_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE CSV SUBMISSION\n",
    "#create_csv_submission(ids_test, y_predicted_test, 'output/trial.csv')\n",
    "\n",
    "# COMPUTE ACCURACY ON FULL train\n",
    "total_accuracy_train = np.sum(y_predicted_train == y_train)/len(y_train)*100\n",
    "print('Total accuracy train =', total_accuracy_train, 'with degrees =', best_degrees, \\\n",
    "      ', gammas =', best_gammas, 'and lambdas =', best_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_accuracy_test = np.sum(y_predicted_test == y_test)/len(y_test)*100\n",
    "print('Total accuracy test =', total_accuracy_test, 'with degrees =', best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(y_predicted_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_test[:200]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
