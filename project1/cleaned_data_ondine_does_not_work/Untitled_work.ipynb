{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing_functions import *\n",
    "#%matplotlib inline \n",
    "import numpy as np   # generic stuff\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#### REMOVE THIS LINE BEFORE SUBMISSION\n",
    "# import pandas as pd\n",
    "#######################################################################\n",
    "\n",
    "from lib.proj1_helpers import * #the helper provided for the project\n",
    "#from lib.costs import *\n",
    "\n",
    "# choose which implementations you would like\n",
    "from lib.implementations import *\n",
    "#from implementations import * #our implementations of the functions done by us\n",
    "\n",
    "\n",
    "#import datetime\n",
    "#import operator\n",
    "#from helpers import * #helpers of exo 2\n",
    "# Useful starting lines\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where to take the data from\n",
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "# Load training and testing data\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_FOLDER+'train.csv',sub_sample=False)\n",
    "\n",
    "# TODOOOOOOOOOO GET RID OF IT BEFORE SUBMITTING CODE!\n",
    "size_train = int(len(y_train)/2)\n",
    "y_test = y_train[:size_train]\n",
    "tx_test = tx_train[:size_train,:]\n",
    "ids_test = ids_train[:size_train]\n",
    "\n",
    "y_train = y_train[size_train:]\n",
    "tx_train = tx_train[size_train:,:]\n",
    "ids_train = ids_train[size_train:]\n",
    "\n",
    "#y_test, tx_test, ids_test = load_csv_data(DATA_FOLDER+'test.csv',sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 30)\n",
      "(125000, 30)\n",
      "(125000,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the data\n",
    "print(tx_train.shape)\n",
    "print(tx_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"Build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_jets_mask(tx):\n",
    "    \"\"\"Creates a mask from array tx corresponding to feature 22 (number of jets).\"\"\"\n",
    "    idx_cat = 22\n",
    "    return {\n",
    "        0: tx[:,idx_cat] == 0,\n",
    "        1: tx[:,idx_cat] == 1,\n",
    "        2: tx[:,idx_cat] == 2,\n",
    "        3: tx[:,idx_cat] == 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_values(tx, mean=False):\n",
    "    \"\"\"Replace missing values (-999) of tx by the mean (if mean==True) or by the median (if mean==False) of the \n",
    "       column in which the missing value belongs.\n",
    "       Returns the modified matrix and a matrix similar to tx but with 1 instead of -999 and 0 otherwise.\"\"\"\n",
    "    \n",
    "    nan_values = (tx==-999)*1\n",
    "    for col in range(tx.shape[1]):\n",
    "        # Select entries of col that have values -999\n",
    "        column = tx[:,col][tx[:,col]!=-999]\n",
    "        \n",
    "        # If the column col contains missing values, replace them by the median or the mean\n",
    "        if len(column) != 0:\n",
    "            if mean==False:\n",
    "                replace_value = np.median(column)\n",
    "            else:\n",
    "                replace_value = np.mean(column)\n",
    "            tx[:,col][tx[:,col]==-999] = replace_value\n",
    "            \n",
    "    return tx, nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_unique_cols(tx):\n",
    "    \"\"\"Input: matrix tx. If two (or more) columns of tx are equal, keep only one of them.\n",
    "       If a column has all of its entries identical, do not keep it (it will be replaced by the column of 1s).\n",
    "       Returns the indices of the kept columns.\"\"\"\n",
    "\n",
    "    unique_cols_ids = [0]\n",
    "    for i in range(1,tx.shape[1]):\n",
    "        # Check if all entries of column i are identical\n",
    "        erase = np.sum((tx[:,i]==tx[0,i])*1)==len(tx[:,i]) \n",
    "        \n",
    "        # If all entries are not identical, check if the column is equal to another one amongst the \n",
    "        # already chosen columns\n",
    "        if erase == False: \n",
    "            id_loop = unique_cols_ids\n",
    "            for j in id_loop:\n",
    "                if np.sum(tx[:,i]-tx[:,j])==0:\n",
    "                    erase = True\n",
    "                    break\n",
    "                    \n",
    "        # If the column is not equal to another one, nor it has all identical entries, keep it\n",
    "        if erase == False: \n",
    "            unique_cols_ids.append(i)\n",
    "    \n",
    "    return unique_cols_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cross_prod(tx, i, j):\n",
    "    \"\"\"Add a column to tx correponding to the product of the entries of the i-th and j-th columns.\"\"\"\n",
    "    return np.concatenate((tx, np.array([tx[:,i]*tx[:,j]]).T), axis=1)\n",
    "\n",
    "def add_all_cross_prod(tx, selected_cols=[]):\n",
    "    \"\"\"Add all products between 2 products\"\"\"\n",
    "    if selected_cols==[]:\n",
    "        selected_cols=range(tx.shape[1])\n",
    "    for idx, i in enumerate(selected_cols):\n",
    "        #print(idx)\n",
    "        for j in selected_cols[idx+1:]:\n",
    "            tx = add_cross_prod(tx, i, j)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the data set x.\"\"\"\n",
    "    # Compute the mean for each column\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    x = x - mean_x\n",
    "    # Compute the standard deviation for each column\n",
    "    std_x = np.std(x, axis=0)\n",
    "    x = x / std_x\n",
    "    return np.array(x), mean_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ones(tx):\n",
    "    \"\"\"Add a column of 1s to matrix tx.\"\"\"\n",
    "    return np.concatenate((tx, np.ones([tx.shape[0],1])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tx, unique_cols=[], stdize=\"before\"):\n",
    "    #print('Cleaning features')\n",
    "    tx, nan_values = clean_missing_values(tx)\n",
    "    np.append(tx, nan_values[:,0]) # Add dummy variable to keep the information saying when the mass is -999 or not\n",
    "    \n",
    "    #print('Keeping unique cols')\n",
    "    if unique_cols==[]:\n",
    "        unique_cols = keep_unique_cols(tx)\n",
    "    tx = tx[:,unique_cols]\n",
    "    len_kept_data = len(unique_cols)\n",
    "    \n",
    "    if stdize=='before':\n",
    "        #print('Standardizing')\n",
    "        tx = standardize(tx)[0]\n",
    "    \n",
    "    # print('Cross products')\n",
    "    tx = add_all_cross_prod(tx)\n",
    "    \n",
    "    if stdize=='after':\n",
    "        #print('Standardizing')\n",
    "        tx = standardize(tx)[0]\n",
    "    \n",
    "    #print('Adding ones')\n",
    "    tx = add_ones(tx)\n",
    "\n",
    "    return tx, len_kept_data, unique_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, range_degrees):\n",
    "    \"\"\"Polynomial basis functions for input array data x.\"\"\"\n",
    "    return np.array([x**p for p in range_degrees]).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_powers(tx, range_degrees, range_col_idx):\n",
    "    if len(range_degrees)>0:\n",
    "        for col_id in range_col_idx:\n",
    "            tx = np.concatenate((tx, build_poly(tx[:,col_id], range_degrees)), axis=1)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_one_fold_LS(y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, \\\n",
    "                                 degrees, len_kept_data, stdize=False):\n",
    "    \n",
    "    accuracies_train_by_deg = np.zeros(len(degrees))\n",
    "    accuracies_test_by_deg = np.zeros(len(degrees))\n",
    "    \n",
    "    # For each degree, compute the least squares weights, the predictions and the accuracies\n",
    "    previous_deg = 1\n",
    "    for deg_id, deg in enumerate(degrees):\n",
    "        print('++ Degree', deg, '++')\n",
    "        \n",
    "        # Add powers of the chosen columns\n",
    "        tx_cross_val_train = add_powers(tx_cross_val_train, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        tx_cross_val_test = add_powers(tx_cross_val_test, range(previous_deg+1, deg+1), range(len_kept_data))\n",
    "        if stdize: ### TO BE CHECKED TODOOOOOOOOOOOOO\n",
    "            tx_cross_val_train = standardize(tx_cross_val_train)[0]\n",
    "            tx_cross_val_test = standardize(tx_cross_val_test)[0]\n",
    "    \n",
    "        # Compute the best weights on the training set\n",
    "        weights, loss = ridge_regression(y_cross_val_train, tx_cross_val_train, 1e-8, fct='mse')\n",
    "        # least_squares(y_cross_val_train, tx_cross_val_train, 'mse') \n",
    "\n",
    "        # Compute the predictions\n",
    "        y_predicted_cross_val_train = predict_labels(weights, tx_cross_val_train)\n",
    "        y_predicted_cross_val_test = predict_labels(weights, tx_cross_val_test)\n",
    "\n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_deg[deg_id] = \\\n",
    "            np.sum(y_predicted_cross_val_train == y_cross_val_train)/len(y_cross_val_train)\n",
    "        accuracies_test_by_deg[deg_id] = \\\n",
    "            np.sum(y_predicted_cross_val_test == y_cross_val_test)/len(y_cross_val_test)\n",
    "        \n",
    "        # Update the previous degree to the actual degree\n",
    "        previous_deg = deg\n",
    "        \n",
    "    return accuracies_train_by_deg, accuracies_test_by_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_least_squares(y_single_jet_train, tx_single_jet_train, degrees, k_fold, seed):\n",
    "    \n",
    "    # Get the indices so that we get the k'th subgroup in test, others in train, for each k\n",
    "    k_indices = build_k_indices(y_single_jet_train, k_fold, seed)\n",
    "    \n",
    "    # Initialize matrix of computed accuracies for each degree and each fold\n",
    "    accuracies_train_by_fold = np.zeros([len(degrees), k_fold])\n",
    "    accuracies_test_by_fold = np.zeros([len(degrees), k_fold])\n",
    "    \n",
    "    # Preprocess training dataset\n",
    "    tx_single_jet_train_preprocessed = np.copy(tx_single_jet_train)\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'none')\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('--- Fold', k, '---')\n",
    "        # Create the testing set for this fold number\n",
    "        k_index = k_indices[k] # Indices of the testing set for fold k\n",
    "        y_cross_val_test = y_single_jet_train[k_index]\n",
    "        tx_cross_val_test = tx_single_jet_train_preprocessed[k_index,:]\n",
    "        \n",
    "        # Create the training set for this fold number\n",
    "        mask = np.ones(len(y_single_jet_train), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False # set test elements to False\n",
    "        y_cross_val_train = y_single_jet_train[mask] # select only True elements (ie train elements)\n",
    "        tx_cross_val_train = tx_single_jet_train_preprocessed[mask,:]    \n",
    "        \n",
    "            \n",
    "        # Preprocess training dataset\n",
    "        #tx_cross_val_train, len_kept_data, unique_cols = \\\n",
    "        #    preprocess_data(tx_cross_val_train, [], 'none')\n",
    "        #tx_cross_val_test = preprocess_data(tx_cross_val_test, unique_cols, 'none')[0]\n",
    "        \n",
    "        # Compute the accuracies for each degree\n",
    "        accuracies_train_by_fold[:,k], accuracies_test_by_fold[:,k] = cross_validation_one_fold_LS\\\n",
    "            (y_cross_val_train, y_cross_val_test, tx_cross_val_train, tx_cross_val_test, degrees, len_kept_data, \\\n",
    "             False)\n",
    "    \n",
    "    # Compute the mean accuracies over the folds, for each degree\n",
    "    mean_accuracies_train_by_deg = np.mean(accuracies_train_by_fold, axis=1)\n",
    "    mean_accuracies_test_by_deg = np.mean(accuracies_test_by_fold, axis=1)\n",
    "    \n",
    "    # Get the index of the best accuracy in the testing set\n",
    "    max_id_deg_test = np.unravel_index(mean_accuracies_test_by_deg.argmax(), mean_accuracies_test_by_deg.shape)\n",
    "    \n",
    "    # Find the optimal degree and the corresponding accuracies in the training and testing sets\n",
    "    best_deg = degrees[max_id_deg_test[0]]\n",
    "    best_accuracy_test = mean_accuracies_test_by_deg[max_id_deg_test[0]]\n",
    "    corresponding_accuracy_train = mean_accuracies_train_by_deg[max_id_deg_test[0]]\n",
    "    \n",
    "    print('Best accuracy test =', best_accuracy_test, 'with degree =', best_deg)\n",
    "    print('Corresponding accuracy train =', corresponding_accuracy_train)\n",
    "    \n",
    "    return best_deg, best_accuracy_test, corresponding_accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = range(6,11)\n",
    "k_fold = 4\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_jets_train = split_jets_mask(tx_train)\n",
    "mask_jets_test = split_jets_mask(tx_test)\n",
    "len_mask = len(mask_jets_train)\n",
    "\n",
    "y_predicted_train = np.zeros(len(y_train))\n",
    "y_predicted_test = np.zeros(tx_test.shape[0])\n",
    "best_degrees = np.zeros(len_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Jet  0 *****\n",
      "--- Fold 0 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 1 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 2 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 3 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "Best accuracy test = 0.841506410256 with degree = 7\n",
      "Corresponding accuracy train = 0.844437767094\n",
      "Accuracy full train on jet 0 = 0.843709935897\n",
      "***** Jet  1 *****\n",
      "--- Fold 0 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 1 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 2 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 3 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "Best accuracy test = 0.798344678218 with degree = 10\n",
      "Corresponding accuracy train = 0.804881402544\n",
      "Accuracy full train on jet 1 = 0.805625741247\n",
      "***** Jet  2 *****\n",
      "--- Fold 0 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 1 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 2 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 3 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "Best accuracy test = 0.837911652945 with degree = 9\n",
      "Corresponding accuracy train = 0.85\n",
      "Accuracy full train on jet 2 = 0.849085727856\n",
      "***** Jet  3 *****\n",
      "--- Fold 0 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 1 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 2 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "--- Fold 3 ---\n",
      "++ Degree 6 ++\n",
      "++ Degree 7 ++\n",
      "++ Degree 8 ++\n",
      "++ Degree 9 ++\n",
      "++ Degree 10 ++\n",
      "Best accuracy test = 0.825535001814 with degree = 9\n",
      "Corresponding accuracy train = 0.859569580462\n",
      "Accuracy full train on jet 3 = 0.854552049329\n"
     ]
    }
   ],
   "source": [
    "for jet_id in range(len_mask):\n",
    "    print('***** Jet ', jet_id, '*****')\n",
    "    # SEPARATE THE WHOLE DATA SET TO GET ONLY THE PART THAT HAVE THE RIGHT NUMBER OF JETS\n",
    "    tx_single_jet_train = tx_train[mask_jets_train[jet_id]]\n",
    "    tx_single_jet_test = tx_test[mask_jets_test[jet_id]]\n",
    "    y_single_jet_train = y_train[mask_jets_train[jet_id]]\n",
    "    \n",
    "    # CALL CROSS VALIDATION FOR A SINGLE JET ON TRAIN PART, FIND BEST DEG, BEST ACCURACY ON TESTING CROSS VAL\n",
    "    best_deg, best_accuracy, corresponding_accuracy_train = cross_validation_least_squares(y_single_jet_train, \\\n",
    "                                                                                           tx_single_jet_train, \\\n",
    "                                                                                           degrees, k_fold, seed)\n",
    "    \n",
    "    # KEEP IN MEMORY THE BEST DEGREE FOR THIS JET\n",
    "    best_degrees[jet_id] = best_deg\n",
    "    \n",
    "    # PREPROCESS FULL TRAINING AND TESTING DATA\n",
    "    tx_single_jet_train_preprocessed, len_kept_data, unique_cols = \\\n",
    "        preprocess_data(tx_single_jet_train, [], 'none')\n",
    "    tx_single_jet_test_preprocessed = preprocess_data(tx_single_jet_test, unique_cols, 'none')[0]\n",
    "    \n",
    "    # ADD POWERS TO THE CHOSEN COLUMNS\n",
    "    tx_single_jet_train_preprocessed = add_powers(tx_single_jet_train_preprocessed, range(2,best_deg+1), \\\n",
    "                                                  range(len_kept_data))\n",
    "    tx_single_jet_test_preprocessed = add_powers(tx_single_jet_test_preprocessed, range(2,best_deg+1), \\\n",
    "                                                 range(len_kept_data))\n",
    "    \n",
    "    # COMPUTE THE BEST WEIGHTS AND FULL ACCURACY ON TRAINING FULL SET - ONE JET\n",
    "    weights, loss = ridge_regression(y_single_jet_train, tx_single_jet_train_preprocessed, 1e-8, fct='mse')\n",
    "    # least_squares(y_single_jet_train, tx_single_jet_train_preprocessed, 'mse')\n",
    "    \n",
    "    # COMPUTE THE PREDICTIONS ON THE FULL TESTING SET - SINGLE JET\n",
    "    y_predicted_single_jet_train = predict_labels(weights, tx_single_jet_train_preprocessed)\n",
    "    y_predicted_single_jet_test = predict_labels(weights, tx_single_jet_test_preprocessed)\n",
    "    \n",
    "    # ADD THE PREDICTIONS TO y_predicted_test AND y_predicted_train\n",
    "    y_predicted_train[mask_jets_train[jet_id]] = y_predicted_single_jet_train\n",
    "    y_predicted_test[mask_jets_test[jet_id]] = y_predicted_single_jet_test\n",
    "    \n",
    "    # COMPUTE THE ACCURACY train ON JET\n",
    "    accuracy_train_single_jet = np.sum(y_predicted_single_jet_train == y_single_jet_train)/len(y_single_jet_train)\n",
    "    \n",
    "    # PRINT ACCURACY train ON JET\n",
    "    print('Accuracy full train on jet', jet_id, '=', accuracy_train_single_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy train = 83.3936 with degrees = [  7.  10.   9.   9.]\n"
     ]
    }
   ],
   "source": [
    "# CREATE CSV SUBMISSION\n",
    "#create_csv_submission(ids_test, y_predicted_test, 'output/trial.csv')\n",
    "\n",
    "# COMPUTE ACCURACY ON FULL train\n",
    "total_accuracy_train = np.sum(y_predicted_train == y_train)/len(y_train)*100\n",
    "print('Total accuracy train =', total_accuracy_train, 'with degrees =', best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy test = 82.6384 with degrees = [  7.  10.   9.   9.]\n"
     ]
    }
   ],
   "source": [
    "total_accuracy_test = np.sum(y_predicted_test == y_test)/len(y_test)*100\n",
    "print('Total accuracy test =', total_accuracy_test, 'with degrees =', best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84973"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_predicted_test==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40027"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_predicted_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
