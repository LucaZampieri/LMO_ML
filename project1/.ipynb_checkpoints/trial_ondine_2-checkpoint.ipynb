{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TODO**\n",
    "* Features cross products\n",
    "* Square and cube roots\n",
    "* phi features overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np   # generic stuff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.proj1_helpers import * #the helper provided for the project\n",
    "\n",
    "from implementations import * #our implementations of the functions done by us\n",
    "from helpers import *\n",
    "import datetime\n",
    "import operator\n",
    "# Useful starting lines\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the training and the testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_FOLDER+'train.csv',sub_sample=False)\n",
    "\n",
    "y_test, tx_test, ids_test = load_csv_data(DATA_FOLDER+'test.csv',sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ..., \n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-999.   ,   79.589,   23.916, ..., -999.   , -999.   ,    0.   ],\n",
       "       [ 106.398,   67.49 ,   87.949, ..., -999.   , -999.   ,   47.575],\n",
       "       [ 117.794,   56.226,   96.358, ..., -999.   , -999.   ,    0.   ],\n",
       "       ..., \n",
       "       [ 108.497,    9.837,   65.149, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  96.711,   20.006,   66.942, ..., -999.   , -999.   ,   30.863],\n",
       "       [  92.373,   80.109,   77.619, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values (-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_missing_values(tx):\n",
    "    nan_values = (tx==-999)*1\n",
    "    for col in range(tx.shape[1]):\n",
    "        column = tx[:,col][tx[:,col]!=-999]\n",
    "        median = np.median(column)\n",
    "        tx[:,col][tx[:,col]==-999] = median\n",
    "    return tx, nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_train, nan_values_train = clean_missing_values(tx_train)\n",
    "tx_test, nan_values_test = clean_missing_values(tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_nan_feature(tx, nan_values):\n",
    "    # Keep in nan_values only the columns containing ones (i.e. keep only columns that used to contain -999)\n",
    "    cols_wo_nan_ids = [i for i in range(nan_values.shape[1]) if np.prod((nan_values.T[i]==0)*1)==1]\n",
    "    nan_values = np.delete(nan_values, cols_wo_nan_ids, axis=1)\n",
    "\n",
    "    # If two (or more) columns of nan_values are equal, keep only one of them\n",
    "    unique_nan_cols_ids = [0]\n",
    "    #erase_cols_ids = []\n",
    "    for i in range(1,nan_values.shape[1]):\n",
    "        id_loop = unique_nan_cols_ids\n",
    "        erase = False\n",
    "        for j in id_loop:\n",
    "            if np.sum(nan_values.T[i]-nan_values.T[j])==0:\n",
    "                #erase_cols_ids.append(i)\n",
    "                erase = True\n",
    "                break\n",
    "        if erase == False:\n",
    "            unique_nan_cols_ids.append(i)\n",
    "    nan_values = nan_values[:,unique_nan_cols_ids]\n",
    "    \n",
    "    # Concatenate nan_values with the original data matrix tx\n",
    "    return np.concatenate((tx, nan_values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000, 33)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "tx_train = add_nan_feature(tx_train, nan_values_train)\n",
    "print(tx_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30)\n",
      "(568238, 33)\n"
     ]
    }
   ],
   "source": [
    "print(tx_test.shape)\n",
    "tx_test = add_nan_feature(tx_test, nan_values_test)\n",
    "print(tx_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage categorical data (feature 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  1., ...,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train[:,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manage_categorical_data(tx):\n",
    "    idx_cat = 22\n",
    "    larger_tx = np.zeros([tx.shape[0],3])\n",
    "    # larger_tx[:,0] = (tx[:,idx_cat]==0)*1 ---> not done, because it is equivalent to a dummy variable due to -999\n",
    "    larger_tx[:,0] = (tx[:,idx_cat]==1)*1\n",
    "    larger_tx[:,1] = (tx[:,idx_cat]==2)*1\n",
    "    larger_tx[:,2] = (tx[:,idx_cat]==3)*1\n",
    "    tx = np.delete(tx, idx_cat, axis=1)\n",
    "    tx = np.concatenate((tx, larger_tx), axis=1)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 33)\n",
      "(250000, 35)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "tx_train = manage_categorical_data(tx_train)\n",
    "print(tx_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 33)\n",
      "(568238, 35)\n"
     ]
    }
   ],
   "source": [
    "print(tx_test.shape)\n",
    "tx_test = manage_categorical_data(tx_test)\n",
    "print(tx_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_train = standardize(tx_train)\n",
    "tx_train = tx_train[0]\n",
    "tx_test = standardize(tx_test)\n",
    "tx_test = tx_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add cross-products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cross_prod(tx, i, j):\n",
    "    return np.concatenate((tx, np.array([tx[:,i]*tx[:,j]]).T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_all_cross_prod(tx):\n",
    "    sh = tx.shape[1]\n",
    "    for i in range(sh):\n",
    "        print(i)\n",
    "        for j in range(i+1, sh):\n",
    "            if i != j:\n",
    "                tx = add_cross_prod(tx, i, j)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "tx_train = add_all_cross_prod(tx_train)\n",
    "tx_test = add_all_cross_prod(tx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a column of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ones(tx):\n",
    "    return np.concatenate((tx, np.ones([tx.shape[0],1])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_train = add_ones(tx_train)\n",
    "tx_test = add_ones(tx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add powers of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=1 up to j=degree.\"\"\"\n",
    "    return np.array([x**p for p in range(2,degree+1)]).T \n",
    "    # not range from 0 because we have already added a column of ones, \n",
    "    # not range from 1 because we already have the linear features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_powers(tx, degree):\n",
    "    for col in range(29): #range(tx.shape[1]):\n",
    "        tx = np.concatenate((tx, build_poly(tx[:,col], degree)), axis=1)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DONE IN CROSS VALIDATION\n",
    "# deg = 11\n",
    "# tx_train = add_powers(tx_train, deg)\n",
    "# tx_test = add_powers(tx_test, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 631)\n",
      "(568238, 631)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "print(tx_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_ridge_regression(y, tx, k_indices, k, lambda_, degree, fct='rmse'):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    k_index = k_indices[k]\n",
    "    test_y = y[k_index]\n",
    "    test_tx = tx[k_index,:]\n",
    "\n",
    "    mask = np.ones(len(y), dtype=bool) # set all elements to True\n",
    "    mask[k_index] = False              # set test elements to False\n",
    "    train_tx = tx[mask,:]              # select only True elements (ie train elements)\n",
    "    train_y = y[mask]\n",
    "    \n",
    "    # ridge regression and\n",
    "    # calculate the loss for train and test data\n",
    "    weights = ridge_regression(train_y, train_tx, lambda_)\n",
    "\n",
    "    y_pred_train = predict_labels(weights, train_tx)\n",
    "    y_pred_test = predict_labels(weights, test_tx)\n",
    "    right_train = np.sum(y_pred_train == train_y)/len(train_y)*100\n",
    "    right_test = np.sum(y_pred_test == test_y)/len(test_y)*100\n",
    "    \n",
    "    return right_train, right_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  1  over  1  ; Degree =  11\n",
      "i =  1  over  1  ; Lambda_ =  1e-11\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "k_fold = 4\n",
    "k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "\n",
    "lambdas = [1e-11] #np.logspace(-15,-3,10)\n",
    "degrees = [11] #range(5,16)\n",
    "\n",
    "right_train_l = np.zeros([len(lambdas), len(degrees)])\n",
    "right_test_l = np.zeros([len(lambdas), len(degrees)])\n",
    "\n",
    "for j,degree in enumerate(degrees):\n",
    "    print('j = ', j+1, ' over ', len(degrees), ' ; Degree = ', degree)\n",
    "    tx_train_pow = add_powers(tx_train, degree)\n",
    "    for i,lambda_ in enumerate(lambdas):\n",
    "        print('i = ', i+1, ' over ', len(lambdas), ' ; Lambda_ = ', lambda_)\n",
    "        right_train = 0\n",
    "        right_test = 0\n",
    "        for k in range(k_fold):\n",
    "            right_train_temp, right_test_temp = cross_validation_ridge_regression(y_train, tx_train_pow, k_indices, k, lambda_, degree)\n",
    "            right_train += right_train_temp\n",
    "            right_test += right_test_temp\n",
    "        right_train_l[i,j] = right_train/k_fold\n",
    "        right_test_l[i,j] = right_test/k_fold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(lambdas, right_train_l[:,0], label='train', color='r')\n",
    "plt.semilogx(lambdas, right_test_l[:,0], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees, right_train_l[0,:], label='train', color='r')\n",
    "plt.plot(degrees, right_test_l[0,:], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(lambdas, np.array(degrees), right_test_l) #, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "        #linewidth=0, antialiased=False)\n",
    "\n",
    "#ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let us compute the results on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.7192\n",
      "82.8568\n",
      "Lambda = 5e-12 ; degree = 11\n"
     ]
    }
   ],
   "source": [
    "max_id_i, max_id_j = np.unravel_index(right_test_l.argmax(), right_test_l.shape)\n",
    "print(right_test_l[max_id_i, max_id_j])\n",
    "print(right_train_l[max_id_i, max_id_j])\n",
    "lambda_ = 5e-12 #lambdas[max_id_i]\n",
    "deg = degrees[max_id_j]\n",
    "print('Lambda =', lambda_, '; degree =', deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_final = add_powers(tx_train, deg)\n",
    "tx_test_final = add_powers(tx_test, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0d5625c49791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ridge_regression' is not defined"
     ]
    }
   ],
   "source": [
    "weights = ridge_regression(y_train, tx_train_final, lambda_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('losses: \\n','\\n\\n','weights: \\n',weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.dot(tx_test_final, weights)[1:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict_labels(weights, tx_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred==-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'output/ridge_regression_ondine_3'\n",
    "create_csv_submission(ids_test, y_pred, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
