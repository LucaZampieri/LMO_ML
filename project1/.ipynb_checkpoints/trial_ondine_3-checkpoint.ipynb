{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TODO**\n",
    "* Features cross products\n",
    "* Square and cube roots\n",
    "* phi features overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np   # generic stuff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.proj1_helpers import * #the helper provided for the project\n",
    "\n",
    "from implementations import * #our implementations of the functions done by us\n",
    "from helpers import *\n",
    "import datetime\n",
    "import operator\n",
    "# Useful starting lines\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the training and the testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_FOLDER+'train.csv',sub_sample=False)\n",
    "\n",
    "y_test, tx_test, ids_test = load_csv_data(DATA_FOLDER+'test.csv',sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ..., \n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-999.   ,   79.589,   23.916, ..., -999.   , -999.   ,    0.   ],\n",
       "       [ 106.398,   67.49 ,   87.949, ..., -999.   , -999.   ,   47.575],\n",
       "       [ 117.794,   56.226,   96.358, ..., -999.   , -999.   ,    0.   ],\n",
       "       ..., \n",
       "       [ 108.497,    9.837,   65.149, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  96.711,   20.006,   66.942, ..., -999.   , -999.   ,   30.863],\n",
       "       [  92.373,   80.109,   77.619, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values (-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_missing_values(tx):\n",
    "    nan_values = (tx==-999)*1\n",
    "    for col in range(tx.shape[1]):\n",
    "        column = tx[:,col][tx[:,col]!=-999]\n",
    "        median = np.median(column)\n",
    "        tx[:,col][tx[:,col]==-999] = median\n",
    "    return tx, nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_train, nan_values_train = clean_missing_values(tx_train)\n",
    "tx_test, nan_values_test = clean_missing_values(tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_nan_feature(tx, nan_values):\n",
    "    # Keep in nan_values only the columns containing ones (i.e. keep only columns that used to contain -999)\n",
    "    cols_wo_nan_ids = [i for i in range(nan_values.shape[1]) if np.prod((nan_values.T[i]==0)*1)==1]\n",
    "    nan_values = np.delete(nan_values, cols_wo_nan_ids, axis=1)\n",
    "\n",
    "    # If two (or more) columns of nan_values are equal, keep only one of them\n",
    "    unique_nan_cols_ids = [0]\n",
    "    #erase_cols_ids = []\n",
    "    for i in range(1,nan_values.shape[1]):\n",
    "        id_loop = unique_nan_cols_ids\n",
    "        erase = False\n",
    "        for j in id_loop:\n",
    "            if np.sum(nan_values.T[i]-nan_values.T[j])==0:\n",
    "                #erase_cols_ids.append(i)\n",
    "                erase = True\n",
    "                break\n",
    "        if erase == False:\n",
    "            unique_nan_cols_ids.append(i)\n",
    "    nan_values = nan_values[:,unique_nan_cols_ids]\n",
    "    \n",
    "    # Concatenate nan_values with the original data matrix tx\n",
    "    return np.concatenate((tx, nan_values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000, 33)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "tx_train = add_nan_feature(tx_train, nan_values_train)\n",
    "print(tx_train.shape)\n",
    "del nan_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30)\n",
      "(568238, 33)\n"
     ]
    }
   ],
   "source": [
    "print(tx_test.shape)\n",
    "tx_test = add_nan_feature(tx_test, nan_values_test)\n",
    "print(tx_test.shape)\n",
    "del nan_values_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage categorical data (feature 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  1., ...,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train[:,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manage_categorical_data(tx):\n",
    "    idx_cat = 22\n",
    "    larger_tx = np.zeros([tx.shape[0],3])\n",
    "    # larger_tx[:,0] = (tx[:,idx_cat]==0)*1 ---> not done, because it is equivalent to a dummy variable due to -999\n",
    "    larger_tx[:,0] = (tx[:,idx_cat]==1)*1\n",
    "    larger_tx[:,1] = (tx[:,idx_cat]==2)*1\n",
    "    larger_tx[:,2] = (tx[:,idx_cat]==3)*1\n",
    "    tx = np.delete(tx, idx_cat, axis=1)\n",
    "    tx = np.concatenate((tx, larger_tx), axis=1)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 33)\n",
      "(250000, 35)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "tx_train = manage_categorical_data(tx_train)\n",
    "print(tx_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 33)\n",
      "(568238, 35)\n"
     ]
    }
   ],
   "source": [
    "print(tx_test.shape)\n",
    "tx_test = manage_categorical_data(tx_test)\n",
    "print(tx_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_train = standardize(tx_train)\n",
    "tx_train = tx_train[0]\n",
    "tx_test = standardize(tx_test)\n",
    "tx_test = tx_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add cross-products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_cross_prod(tx, i, j):\n",
    "    return np.concatenate((tx, np.array([tx[:,i]*tx[:,j]]).T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_all_cross_prod(tx):\n",
    "    sh = tx.shape[1]\n",
    "    for i in range(sh):\n",
    "        print(i)\n",
    "        for j in range(i+1, sh):\n",
    "            if i != j:\n",
    "                tx = add_cross_prod(tx, i, j)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "tx_train = add_all_cross_prod(tx_train)\n",
    "tx_test = add_all_cross_prod(tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 630)\n",
      "(568238, 630)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "print(tx_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a column of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ones(tx):\n",
    "    return np.concatenate((tx, np.ones([tx.shape[0],1])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_train = add_ones(tx_train)\n",
    "tx_test = add_ones(tx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not to have to compute it each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.savetxt(\"data/tx_train_uptoones.csv\", tx_train, delimiter=\",\")\n",
    "# np.savetxt(\"data/tx_test_uptoones.csv\", tx_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!! one can begin directly here, after loading y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tx_train = genfromtxt('data/tx_train_uptoones.csv', delimiter=',')\n",
    "#tx_test = genfromtxt('data/tx_test_uptoones.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add powers of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=1 up to j=degree.\"\"\"\n",
    "    return np.array([x**p for p in range(2,degree+1)]).T \n",
    "    # not range from 0 because we have already added a column of ones, \n",
    "    # not range from 1 because we already have the linear features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_powers(tx, degree):\n",
    "    for col in range(29): #range(tx.shape[1]):\n",
    "        tx = np.concatenate((tx, build_poly(tx[:,col], degree)), axis=1)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DONE IN CROSS VALIDATION\n",
    "# deg = 11\n",
    "# tx_train = add_powers(tx_train, deg)\n",
    "# tx_test = add_powers(tx_test, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 631)\n",
      "(568238, 631)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "print(tx_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_ridge_regression(y, tx, k_indices, k, lambda_, degree, fct='rmse'):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    k_index = k_indices[k]\n",
    "    test_y = y[k_index]\n",
    "    test_tx = tx[k_index,:]\n",
    "\n",
    "    mask = np.ones(len(y), dtype=bool) # set all elements to True\n",
    "    mask[k_index] = False              # set test elements to False\n",
    "    train_tx = tx[mask,:]              # select only True elements (ie train elements)\n",
    "    train_y = y[mask]\n",
    "    \n",
    "    # ridge regression and\n",
    "    # calculate the loss for train and test data\n",
    "    weights = ridge_regression(train_y, train_tx, lambda_)\n",
    "\n",
    "    y_pred_train = predict_labels(weights, train_tx)\n",
    "    y_pred_test = predict_labels(weights, test_tx)\n",
    "    right_train = np.sum(y_pred_train == train_y)/len(train_y)*100\n",
    "    right_test = np.sum(y_pred_test == test_y)/len(test_y)*100\n",
    "    \n",
    "    return right_train, right_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  1  over  1  ; Degree =  11\n",
      "i =  1  over  1  ; Lambda_ =  1e-11\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "k_fold = 4\n",
    "k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "\n",
    "lambdas = [1e-11] #np.logspace(-15,-3,10)\n",
    "degrees = [11] #range(5,16)\n",
    "\n",
    "right_train_l = np.zeros([len(lambdas), len(degrees)])\n",
    "right_test_l = np.zeros([len(lambdas), len(degrees)])\n",
    "\n",
    "for j,degree in enumerate(degrees):\n",
    "    print('j = ', j+1, ' over ', len(degrees), ' ; Degree = ', degree)\n",
    "    tx_train_pow = add_powers(tx_train, degree)\n",
    "    for i,lambda_ in enumerate(lambdas):\n",
    "        print('i = ', i+1, ' over ', len(lambdas), ' ; Lambda_ = ', lambda_)\n",
    "        right_train = 0\n",
    "        right_test = 0\n",
    "        for k in range(k_fold):\n",
    "            right_train_temp, right_test_temp = cross_validation_ridge_regression(y_train, tx_train_pow, k_indices, k, lambda_, degree)\n",
    "            right_train += right_train_temp\n",
    "            right_test += right_test_temp\n",
    "        right_train_l[i,j] = right_train/k_fold\n",
    "        right_test_l[i,j] = right_test/k_fold\n",
    "    del tx_train_pow, right_train, right_test, right_train_temp, right_test_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.semilogx(lambdas, right_train_l[:,0], label='train', color='r')\n",
    "plt.semilogx(lambdas, right_test_l[:,0], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(degrees, right_train_l[0,:], label='train', color='r')\n",
    "plt.plot(degrees, right_test_l[0,:], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(lambdas, np.array(degrees), right_test_l) #, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "        #linewidth=0, antialiased=False)\n",
    "\n",
    "#ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let us compute the results on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.7192\n",
      "82.8568\n",
      "Lambda = 1e-11 ; degree = 11\n"
     ]
    }
   ],
   "source": [
    "max_id_i, max_id_j = np.unravel_index(right_test_l.argmax(), right_test_l.shape)\n",
    "print(right_test_l[max_id_i, max_id_j])\n",
    "print(right_train_l[max_id_i, max_id_j])\n",
    "lambda_ = lambdas[max_id_i] #5e-12\n",
    "deg = degrees[max_id_j]\n",
    "print('Lambda =', lambda_, '; degree =', deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_final = add_powers(tx_train, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_test_final = add_powers(tx_test, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = ridge_regression(y_train, tx_train_final, lambda_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('losses: \\n','\\n\\n','weights: \\n',weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.69567033e-01,   6.46332011e-01,   1.33137182e+00,\n",
       "         4.12543924e+00,  -6.50421032e-01,   1.28562554e-03,\n",
       "         8.90425884e-01,  -5.26566930e-01,   3.04101345e+00,\n",
       "         4.89429752e-01,   3.08869591e-01,   3.67544406e-01,\n",
       "         1.35935090e-02,  -3.85350931e-01,  -2.97960942e-01,\n",
       "        -5.54317822e-02,  -6.25368070e-01,   6.61107821e-04,\n",
       "         9.98388417e-01,   5.29671267e-01,  -2.00773583e-01,\n",
       "         2.12201558e+00,   2.57019549e-01,   5.14724900e-01,\n",
       "         1.67322702e+00,   1.67154191e+00,   1.61632174e-01,\n",
       "         2.95950168e+00,   1.60976563e-01,  -4.07984928e-01,\n",
       "         6.15543819e-01,   4.97076646e-01,   1.52679716e+00,\n",
       "        -7.51824785e-02,   1.18017859e+00,  -6.58770017e-01,\n",
       "         2.04309068e-01,   9.62632972e-01,  -2.77300421e-01,\n",
       "         8.28449118e-01,   1.76037228e-01,  -2.92609771e-01,\n",
       "         7.89411423e-01,   7.26609951e-01,   6.36788823e-01,\n",
       "        -2.02501641e-02,   2.48997869e+00,   2.29483284e+00,\n",
       "        -3.22296525e-01,   6.07772475e-01,   1.09002357e+00,\n",
       "         1.25880642e+00,   2.51536480e+00,   2.38065110e+00,\n",
       "        -1.22485341e+00,   3.58204032e-01,  -3.57685448e-01,\n",
       "         9.00631485e-01,   4.80019078e-01,   3.20477565e-01,\n",
       "         5.72965307e-01,   2.41809569e+00,   5.51089199e-01,\n",
       "         4.62466585e+00,   4.79742569e-01,  -3.04571975e-01,\n",
       "         5.31824519e+00,   2.32875835e+00,   1.61646757e+00,\n",
       "         2.04134774e+00,   8.20568434e-01,   1.53861575e+00,\n",
       "         3.70173504e-01,  -4.86286073e-01,   1.44834099e+00,\n",
       "        -8.73775390e-01,   3.48003375e-01,   2.05385104e+00,\n",
       "         1.76779273e+00,  -2.21630129e-01,   2.93651503e+00,\n",
       "        -2.40137208e-01,   2.21806406e+00,   1.59013543e+00,\n",
       "         2.83209851e+00,   7.70160881e-02,   4.49689750e-01,\n",
       "         2.21728987e+00,   3.10214823e-01,  -6.26658964e-01,\n",
       "         1.59631353e+00,   9.01362995e-02,   2.53392754e-01,\n",
       "         1.15680539e-01,   1.28065556e+00,   1.76970553e-01,\n",
       "         1.01893860e+00,   1.05009568e+00,   2.61453586e+00,\n",
       "         6.76679209e-01,  -1.20609054e-01,   1.42206151e+00,\n",
       "         6.53662468e-02,  -3.87576259e-01,  -4.82610820e-01,\n",
       "         3.01174955e+00,   1.08635845e+00,   3.12783033e-01,\n",
       "         2.45573896e+00,   4.36926478e-01,   7.11953209e-01,\n",
       "        -4.69262999e-01,   7.52581043e-03,   3.11142942e+00,\n",
       "         1.44428832e+00,   1.26848020e+00,   2.54039237e+00,\n",
       "         2.70717270e+00,   2.46762709e-01,   1.15485734e+00,\n",
       "        -6.51020176e-01,   1.34808033e-02,   7.28330571e-01,\n",
       "         4.26932039e-01,   1.11788207e+00,  -1.91271365e-01,\n",
       "         1.05190184e+00,   6.23488435e-01,   5.96947805e+00,\n",
       "        -2.16191277e-01,   2.78937827e+00,   3.02389620e+00,\n",
       "        -6.52158195e-02,  -1.78123841e-01,  -5.07054924e-01,\n",
       "         9.92925327e-01,   3.30771596e+00,   2.61103468e-01,\n",
       "         8.36602169e-01,   9.86642538e-01,   2.22981978e+00,\n",
       "        -7.78626125e-01,  -5.42568967e-01,  -9.57370119e-02,\n",
       "         8.21365991e-01,   6.11691552e-01,  -7.04381732e-01,\n",
       "         2.34143493e+00,   4.58967145e-01,   5.35079386e-01,\n",
       "         8.39568118e-01,   3.25111221e+00,  -6.06057223e-01,\n",
       "         1.08238649e+00,   3.07194442e-01,  -4.81021426e-01,\n",
       "         1.30826721e+00,   1.29597470e+00,  -1.11525496e-01,\n",
       "        -5.95948269e-02,   4.31463061e+00,  -6.55853280e-01,\n",
       "         1.02977734e+00,   4.32920910e-01,   3.34274288e-01,\n",
       "        -4.95331810e-01,  -9.69690932e-01,   6.22533762e-01,\n",
       "         1.40930425e+00,  -6.16106703e-01,  -6.85528290e-01,\n",
       "         4.27968213e+00,   1.26924000e+00,   1.37793447e+00,\n",
       "        -4.90509429e-01,   1.41438652e+00,  -7.77620698e-01,\n",
       "         1.04770949e+00,   1.63419210e+00,   2.83655239e+00,\n",
       "         1.32747129e+00,   4.37184263e-01,  -3.24672582e-01,\n",
       "         1.23775049e-01,  -4.80254328e-01,   1.81710832e+00,\n",
       "         5.38570532e-01,  -4.88986963e-01,   1.83277796e+00,\n",
       "        -4.03577855e-02,   2.05310622e+00,   9.43342634e-01,\n",
       "         7.51828096e-01,  -5.40502237e-01,  -4.45969940e-01,\n",
       "        -5.14418476e-01,   6.32864031e-01,   1.37649918e+00,\n",
       "         7.22722913e-01])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(tx_test_final, weights)[1:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict_labels(weights, tx_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133012,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred==-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435226,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'output/ridge_regression_ondine_4'\n",
    "create_csv_submission(ids_test, y_pred, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
