{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TODO**\n",
    "* phi features overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.proj1_helpers import * #the helper provided for the project\n",
    "\n",
    "from implementations import * #our implementations of the functions done by us\n",
    "from helpers import *\n",
    "import datetime\n",
    "import operator\n",
    "# Useful starting lines\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the training and the testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_FOLDER+'train.csv',sub_sample=True) # FALSE\n",
    "\n",
    "y_test, tx_test, ids_test = load_csv_data(DATA_FOLDER+'test.csv',sub_sample=True) # FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 219.057,   72.461,  124.835, ..., -999.   , -999.   ,   50.396],\n",
       "       [  90.801,   27.787,   65.373, ..., -999.   , -999.   ,   62.766],\n",
       "       ..., \n",
       "       [ 142.347,    7.389,   99.212, ..., -999.   , -999.   ,   97.068],\n",
       "       [  78.162,   46.335,   60.136, ..., -999.   , -999.   ,   32.44 ],\n",
       "       [ 130.042,    4.073,   67.819, ..., -999.   , -999.   ,   51.037]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.99000000e+02,   7.95890000e+01,   2.39160000e+01, ...,\n",
       "         -9.99000000e+02,  -9.99000000e+02,   0.00000000e+00],\n",
       "       [  1.08035000e+02,   2.90780000e+01,   8.29790000e+01, ...,\n",
       "         -9.99000000e+02,  -9.99000000e+02,   0.00000000e+00],\n",
       "       [  1.18966000e+02,   7.72180000e+01,   9.91180000e+01, ...,\n",
       "         -2.28000000e-01,   1.13000000e-01,   7.14220000e+01],\n",
       "       ..., \n",
       "       [  5.87880000e+01,   5.68600000e+01,   4.60600000e+01, ...,\n",
       "         -9.99000000e+02,  -9.99000000e+02,   0.00000000e+00],\n",
       "       [  8.06430000e+01,   4.21180000e+01,   4.40350000e+01, ...,\n",
       "         -1.91600000e+00,  -2.76400000e+00,   7.87120000e+01],\n",
       "       [  1.14108000e+02,   7.00280000e+01,   6.71570000e+01, ...,\n",
       "         -7.43000000e-01,   3.28000000e-01,   2.05164000e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 30)\n",
      "(11365, 30)\n",
      "(5000,)\n",
      "(11365,)\n"
     ]
    }
   ],
   "source": [
    "print(tx_train.shape)\n",
    "print(tx_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_jets_mask(tx):\n",
    "    idx_cat = 22\n",
    "    return {\n",
    "        0: tx[:,idx_cat] == 0,\n",
    "        1: tx[:,idx_cat] == 1,\n",
    "        2: tx[:,idx_cat] == 2,\n",
    "        3: tx[:,idx_cat] == 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_missing_values(tx):\n",
    "    nan_values = (tx==-999)*1\n",
    "    for col in range(tx.shape[1]):\n",
    "        column = tx[:,col][tx[:,col]!=-999]\n",
    "        if len(column) == 0:\n",
    "            median = 0\n",
    "        else:\n",
    "            median = np.median(column)\n",
    "        tx[:,col][tx[:,col]==-999] = median\n",
    "    return tx, nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_unique_cols(tx):\n",
    "    # If two (or more) columns of tx are equal, keep only one of them\n",
    "    unique_cols_ids = [0]\n",
    "    for i in range(1,tx.shape[1]):\n",
    "        id_loop = unique_cols_ids\n",
    "        erase = False\n",
    "        equal_to = []\n",
    "        for j in id_loop:\n",
    "            if np.sum(tx[:,i]-tx[:,j])==0:\n",
    "                erase = True\n",
    "                equal_to.append(j)\n",
    "                break\n",
    "        if erase == False:\n",
    "            unique_cols_ids.append(i)\n",
    "        #else:\n",
    "        #    print('column', i, 'deleted because equal to column(s) ', equal_to)\n",
    "            \n",
    "    index = np.argwhere(unique_cols_ids==22)\n",
    "    unique_cols_ids = np.delete(unique_cols_ids, index)\n",
    "    \n",
    "    return unique_cols_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add cross products between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_cross_prod(tx, i, j):\n",
    "    return np.concatenate((tx, np.array([tx[:,i]*tx[:,j]]).T), axis=1)\n",
    "\n",
    "def add_all_cross_prod(tx):\n",
    "    sh = tx.shape[1]\n",
    "    for i in range(sh):\n",
    "        #print(i)\n",
    "        for j in range(i+1, sh):\n",
    "            if i != j:\n",
    "                tx = add_cross_prod(tx, i, j)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build powers of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=1 up to j=degree.\"\"\"\n",
    "    return np.array([x**p for p in range(2,degree+1)]).T \n",
    "    # not range from 0 because we have already added a column of ones, \n",
    "    # not range from 1 because we already have the linear features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_powers(tx, degree, first_data_id, len_init_data, features='x'):\n",
    "    if features == 'x': # square roots of initial (kept) features\n",
    "        range_c = range(first_data_id, first_data_id+len_init_data)\n",
    "    elif features == 'cp': # square roots of cross products\n",
    "        range_c = range(first_data_id, first_data_id+(len_init_data*(len_init_data-1))/2)\n",
    "    else:\n",
    "        raise NameError('Need to specity x (features) of cp (cross products)')\n",
    "    for col in range_c: \n",
    "        tx = np.concatenate((tx, build_poly(tx[:,col], degree)), axis=1)\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add column of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ones(tx):\n",
    "    return np.concatenate((tx, np.ones([tx.shape[0],1])), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build square roots of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_square_root(tx, first_data_id, len_init_data, features='x'):\n",
    "    if features == 'x': # square roots of initial (kept) features\n",
    "        range_c = range(first_data_id, first_data_id+len_init_data)\n",
    "    elif features == 'cp': # square roots of cross products\n",
    "        range_c = range(first_data_id, first_data_id+(len_init_data*(len_init_data-1))/2)\n",
    "    else:\n",
    "        raise NameError('Need to specity x (features) of cp (cross products)')\n",
    "    sqrt_array = np.array([np.sqrt(tx[:,c]) for c in range_c].T)\n",
    "    return np.concatenate((tx, sqrt_array), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the step of data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_tx, test_tx, deg):\n",
    "    print('Cleaning features')\n",
    "    train_tx = clean_missing_values(train_tx)[0]\n",
    "    test_tx = clean_missing_values(test_tx)[0]\n",
    "    \n",
    "    print('Keeping unique cols')\n",
    "    unique_cols = keep_unique_cols(train_tx)\n",
    "    train_tx = train_tx[:,unique_cols]\n",
    "    test_tx = test_tx[:,unique_cols]\n",
    "    len_kept_data = len(unique_cols)\n",
    "    \n",
    "    print('Standardizing')\n",
    "    train_tx = standardize(train_tx)[0]\n",
    "    test_tx = standardize(test_tx)[0]\n",
    "    \n",
    "    print('Cross products')\n",
    "    train_tx = add_all_cross_prod(train_tx)\n",
    "    test_tx = add_all_cross_prod(test_tx)\n",
    "    #len_data_with_cp = train_tx.shape[1]\n",
    "    \n",
    "    print('Adding powers')\n",
    "    train_tx = add_powers(train_tx, deg, 0, len_kept_data, 'x')\n",
    "    test_tx = add_powers(test_tx, deg, 0, len_kept_data, 'x')\n",
    "    \n",
    "    print('Adding ones')\n",
    "    train_tx = add_ones(train_tx)\n",
    "    test_tx = add_ones(test_tx)\n",
    "    \n",
    "    return train_tx, test_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_ridge_regression_pred(single_degree, single_lambda, single_train_tx, single_test_tx, \\\n",
    "                                  single_train_y, single_test_y=[], predictions=True):\n",
    "    # Clean and prepare data !!!!!!!!!TODO!!!!!!!!!! NOT HERE WOULD BE MORE EFFICIENT.......\n",
    "    single_train_tx, single_test_tx = prepare_data(single_train_tx, single_test_tx, single_degree)\n",
    "\n",
    "    # Compute the weights with ridge regression\n",
    "#    print(np.linalg.eigvals(single_train_tx.T.dot(single_train_tx)))#\\\n",
    "#          +2*len(single_train_y)*single_lambda*np.matlib.identity(single_train_tx.shape[1])))\n",
    "    weights = ridge_regression(single_train_y, single_train_tx, single_lambda)\n",
    "\n",
    "    # Compute the predictions\n",
    "    y_pred_train = predict_labels(weights, single_train_tx)\n",
    "    y_pred_test = predict_labels(weights, single_test_tx)\n",
    "    \n",
    "    # Compute accuracy of the predictions\n",
    "    accuracy_train = np.sum(y_pred_train == single_train_y)/len(single_train_y)\n",
    "    if len(single_test_y) != 0:\n",
    "        accuracy_test = np.sum(y_pred_test == single_test_y)/len(single_test_y)\n",
    "        if predictions==True:\n",
    "            return y_pred_train, y_pred_test, accuracy_train, accuracy_test\n",
    "        else:\n",
    "            return accuracy_train, accuracy_test\n",
    "    else:\n",
    "        if predictions==True:\n",
    "            return y_pred_train, y_pred_test, accuracy_train\n",
    "        else:\n",
    "            return accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_single_jet_single_param_ridge_regression(single_jet_y, single_jet_tx, k_fold, seed, \\\n",
    "                                                              single_degree, single_lambda):\n",
    "    # get k'th subgroup in test, others in train\n",
    "    k_indices = build_k_indices(single_jet_y, k_fold, seed)\n",
    "    accuracy_train = np.zeros(k_fold)\n",
    "    accuracy_test = np.zeros(k_fold)\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        print('----- FOLD', k, '-----')\n",
    "        k_index = k_indices[k]\n",
    "        test_y = single_jet_y[k_index]\n",
    "        test_tx = single_jet_tx[k_index,:]\n",
    "\n",
    "        mask = np.ones(len(single_jet_y), dtype=bool) # set all elements to True\n",
    "        mask[k_index] = False              # set test elements to False\n",
    "        train_tx = single_jet_tx[mask,:]              # select only True elements (ie train elements)\n",
    "        train_y = single_jet_y[mask]\n",
    "\n",
    "        accuracy_train[k], accuracy_test[k] = \\\n",
    "            cleaned_ridge_regression_pred(single_degree, single_lambda, train_tx, test_tx, train_y, test_y, \\\n",
    "                                          predictions=False)\n",
    "            \n",
    "    return np.mean(accuracy_train), np.mean(accuracy_test), np.var(accuracy_train), np.var(accuracy_test), \\\n",
    "           np.min(accuracy_train), np.min(accuracy_test), np.max(accuracy_train), np.max(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_single_jet_ridge_regression(degrees, lambdas, y_single_jet_train, tx_single_jet_train, \\\n",
    "                                                 k_fold, seed, returnAll=False):\n",
    "    mean_acc_cv_train = np.zeros([len(degrees), len(lambdas)])\n",
    "    mean_acc_cv_test = np.zeros([len(degrees), len(lambdas)])\n",
    "    var_acc_cv_train = np.zeros([len(degrees), len(lambdas)])\n",
    "    var_acc_cv_test = np.zeros([len(degrees), len(lambdas)])\n",
    "    min_acc_cv_train = np.zeros([len(degrees), len(lambdas)])\n",
    "    min_acc_cv_test = np.zeros([len(degrees), len(lambdas)])\n",
    "    max_acc_cv_train = np.zeros([len(degrees), len(lambdas)])\n",
    "    max_acc_cv_test = np.zeros([len(degrees), len(lambdas)])\n",
    "    \n",
    "    for i, single_degree in enumerate(degrees):\n",
    "        print('--- DEGREE', single_degree, '---')\n",
    "        for j, single_lambda in enumerate(lambdas):\n",
    "            print('--- LAMBDA', single_lambda, '---')\n",
    "            mean_acc_cv_train[i,j], mean_acc_cv_test[i,j], var_acc_cv_train[i,j], var_acc_cv_test[i,j], \\\n",
    "                min_acc_cv_train[i,j], min_acc_cv_test[i,j], max_acc_cv_train[i,j], max_acc_cv_test[i,j] = \\\n",
    "                cross_validation_single_jet_single_param_ridge_regression(y_single_jet_train, tx_single_jet_train, \\\n",
    "                                                                          k_fold, seed, single_degree, single_lambda)\n",
    "\n",
    "    max_id_deg, max_id_lambda = np.unravel_index(mean_acc_cv_test.argmax(), mean_acc_cv_test.shape)\n",
    "    print('Best mean accuracy: ', mean_acc_cv_test[max_id_deg, max_id_lambda])\n",
    "    print('attained with degree =', degrees[max_id_deg], 'and lambda =', lambdas[max_id_lambda])\n",
    "\n",
    "    if returnAll == True:\n",
    "        return degrees[max_id_deg], lambdas[max_id_lambda], mean_acc_cv_train, mean_acc_cv_test, var_acc_cv_train, \\\n",
    "               var_acc_cv_test, min_acc_cv_train, min_acc_cv_test, max_acc_cv_train, max_acc_cv_test\n",
    "    else:\n",
    "        return degrees[max_id_deg], lambdas[max_id_lambda], mean_acc_cv_train[max_id_deg, max_id_lambda], \\\n",
    "               mean_acc_cv_test[max_id_deg, max_id_lambda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_all_jets_ridge_regression(degrees, lambdas, k_fold, seed, full_y_train, full_tx_train, \\\n",
    "                                               full_tx_test):\n",
    "    mask_jets_train = split_jets_mask(full_tx_train)\n",
    "    mask_jets_test = split_jets_mask(full_tx_test)\n",
    "    \n",
    "    len_mask = len(mask_jets_train)\n",
    "    best_degree = np.zeros(len_mask)\n",
    "    best_lambda = np.zeros(len_mask)\n",
    "    best_acc_train = np.zeros(len_mask)\n",
    "    best_acc_test = np.zeros(len_mask)\n",
    "    len_jets_train = np.zeros(len_mask)\n",
    "    len_jets_test = np.zeros(len_mask)\n",
    "\n",
    "    for mask_jet_id in range(len_mask):\n",
    "        print('********** Jet ', mask_jet_id, '***********')\n",
    "        tx_single_jet_train = full_tx_train[mask_jets_train[mask_jet_id]]\n",
    "        tx_single_jet_test = full_tx_test[mask_jets_test[mask_jet_id]]\n",
    "        y_single_jet_train = full_y_train[mask_jets_train[mask_jet_id]]\n",
    "        len_jets_train[mask_jet_id] = len(y_single_jet_train)\n",
    "        len_jets_test[mask_jet_id] = tx_single_jet_test.shape[0]\n",
    "        \n",
    "        best_degree[mask_jet_id], best_lambda[mask_jet_id], best_acc_train[mask_jet_id], best_acc_test[mask_jet_id] = \\\n",
    "            cross_validation_single_jet_ridge_regression(degrees, lambdas, y_single_jet_train, tx_single_jet_train, \\\n",
    "                                                         k_fold, seed, returnAll=False)\n",
    "    best_degree = best_degree.astype(int)\n",
    "    best_full_accuracy_train = \\\n",
    "        np.sum([best_acc_train[id]*len_jets_train[id] for id in range(len_mask)])/len(full_y_train)\n",
    "    best_full_accuracy_test = \\\n",
    "        np.sum([best_acc_test[id]*len_jets_test[id] for id in range(len_mask)])/full_tx_test.shape[0]\n",
    "        \n",
    "    return best_degree, best_lambda, best_full_accuracy_train, best_full_accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression_all_jets_pred(full_tx_train, full_tx_test, full_y_train, degrees, lambdas):\n",
    "    mask_jets_train = split_jets_mask(full_tx_train)\n",
    "    mask_jets_test = split_jets_mask(full_tx_test)\n",
    "    \n",
    "    len_mask = len(mask_jets_train)\n",
    "    y_pred_train = np.zeros(len(full_y_train))\n",
    "    y_pred_test = np.zeros(full_tx_test.shape[0])\n",
    "    accuracy_train = np.zeros(len_mask)\n",
    "    len_jets_train = np.zeros(len_mask)\n",
    "    \n",
    "    for mask_jet_id in range(len_mask):\n",
    "        print('********** Jet ', mask_jet_id, '***********')\n",
    "        tx_single_jet_train = full_tx_train[mask_jets_train[mask_jet_id]]\n",
    "        tx_single_jet_test = full_tx_test[mask_jets_test[mask_jet_id]]\n",
    "        y_single_jet_train = full_y_train[mask_jets_train[mask_jet_id]]\n",
    "        len_jets_train[mask_jet_id] = len(y_single_jet_train)\n",
    "        \n",
    "        y_pred_train[mask_jets_train[mask_jet_id]], y_pred_test[mask_jets_test[mask_jet_id]], \\\n",
    "            accuracy_train[mask_jet_id] = cleaned_ridge_regression_pred(degrees[mask_jet_id], lambdas[mask_jet_id], \\\n",
    "                                                                        tx_single_jet_train, tx_single_jet_test, \\\n",
    "                                                                        y_single_jet_train, [], predictions=True)\n",
    "    \n",
    "    full_accuracy_train = \\\n",
    "        np.sum([accuracy_train[id]*len_jets_train[id] for id in range(len_mask)])/len(full_y_train)\n",
    "        \n",
    "    return y_pred_train, y_pred_test, full_accuracy_train\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Jet  0 ***********\n",
      "--- DEGREE 11 ---\n",
      "--- LAMBDA 1 ---\n",
      "----- FOLD 0 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "----- FOLD 1 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "Best mean accuracy:  0.839213709677\n",
      "attained with degree = 11 and lambda = 1\n",
      "********** Jet  1 ***********\n",
      "--- DEGREE 11 ---\n",
      "--- LAMBDA 1 ---\n",
      "----- FOLD 0 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "----- FOLD 1 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "Best mean accuracy:  0.642857142857\n",
      "attained with degree = 11 and lambda = 1\n",
      "********** Jet  2 ***********\n",
      "--- DEGREE 11 ---\n",
      "--- LAMBDA 1 ---\n",
      "----- FOLD 0 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "----- FOLD 1 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "Best mean accuracy:  0.532629558541\n",
      "attained with degree = 11 and lambda = 1\n",
      "********** Jet  3 ***********\n",
      "--- DEGREE 11 ---\n",
      "--- LAMBDA 1 ---\n",
      "----- FOLD 0 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "----- FOLD 1 -----\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "Best mean accuracy:  0.497685185185\n",
      "attained with degree = 11 and lambda = 1\n"
     ]
    }
   ],
   "source": [
    "degrees = range(5,13)\n",
    "lambdas = np.logspace(-12,-3,10)\n",
    "k_fold = 4\n",
    "seed = 1\n",
    "\n",
    "best_degree, best_lambda, best_mean_accuracy_train, best_mean_accuracy_test = \\\n",
    "    cross_validation_all_jets_ridge_regression(degrees, lambdas, k_fold, seed, y_train, tx_train, tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879653233554\n",
      "0.685031243472\n",
      "[11 11 11 11]\n",
      "[ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(best_mean_accuracy_train)\n",
    "print(best_mean_accuracy_test)\n",
    "print(best_degree)\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Jet  0 ***********\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "********** Jet  1 ***********\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "********** Jet  2 ***********\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n",
      "********** Jet  3 ***********\n",
      "Cleaning features\n",
      "Keeping unique cols\n",
      "Standardizing\n",
      "Cross products\n",
      "Adding powers\n",
      "Adding ones\n"
     ]
    }
   ],
   "source": [
    "y_pred_train, y_pred_test, full_accuracy_train, = \\\n",
    "    ridge_regression_all_jets_pred(tx_train, tx_test, y_train, best_degree, best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8938\n"
     ]
    }
   ],
   "source": [
    "print(full_accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1.\n",
      " -1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1.\n",
      " -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1.\n",
      "  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      " -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11365,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7677,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test[y_pred_test==-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3688,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test[y_pred_test==1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'output/ridge_regression_ondine_splitjet.csv'\n",
    "create_csv_submission(ids_test, y_pred_test, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
