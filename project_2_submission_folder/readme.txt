*** README for the 1st Machine Learning Project, finding the Higgs boson --- Team “..no party!!”


The .zip folder is organized according to the following structure: 

- “Image_processing_KNN/”: folder which contains all the codes to run prediction model base on KNN feature extraction with “Image processing”;

- “CNN”: older which contains all the codes to run prediction model base on CONVOLUTIONAL NEURAL NETWORK. Code used for the submission


almostIT.zip
  |—Image_processing_KNN
  |   |—- GMM+KNN.ipynb
  |   |—- KNN.ipnyb
  |   |—- Image_processing_pre_proc.ipynb
  |   |—- feature_extraction.py
  |   |-- feature_increase.py
  |   |—- fill_the_gaps.py 
  |   |—- GMM_functions.py
  |   |—- helper_functions.py 
  |   |—- mask_to_submission.py
  |   |—- image_predicted
  |   |—- test_set_images
  |   |—- training



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

INSIDE “Image_processing_KNN” :    subfolders: “image_predicted”, “test_set_images”, ”training”; 
                           
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

EXTERNAL LIBRARIES USED: Panda, Ski-learn, opencv2


SUBFOLDERS:

- “image_predicted”: it contains the predicted ground-truth for test; 
-  “test_set_images”: it contains the RGB images for test data set
-  “training” : it contains the RGB images for training set as well as the ground-truts


FILES:

1) KNN.ipnyb: contains the code to run KNN. The structure of the code is the following:
		   - Load the data of the “training set” and “test set”,
		   - Extract the labels for the training set with the ground-truths
                   - Extract the features for “Training set” and “Test set” 
                   - Run the cross validation on KNN for determining: “degree of the polynomial matrix” , the best number of neighbors to consider;
		   - With the optimal parameters fit the model on the training set;
		   - Make the prediction 
		   - Save the label of each patch [1,0] as black- and white picture and save this predicted images in “image_predicted”;
                   - Post Processing: fill_the_gaps; the images are saved in the principal folder;
                   - Create the submission on this image ;           IMPORTANT !!! : for the submission be aware that no file .png is present inside the folder except the ones 
										     generated by the code


		
2) GMM+KNN.ipynb: contains the code to run KNN. The structure of the code is the following:
	           - Load the data of the “training set” and “test set”,
                   - Extract the features for “Training set” and “Test set” 
		   - Extract the labels for the training set with the ground-truths
                   - Run the cross validation on for determining: “degree of the polynomial matrix” , the best number of neighbors to consider, the best number of clusters in which the image has to be 			segmented; 
	           - With the optimal number of clusters enhance the training set with GMM functions ( see GMM_function.py ) 
		   - With the optimal parameters fit the model on the training set;
		   - Make the prediction;
		   - Save the label of each patch [1,0] as black- and white picture (the also save the images on image_predicted);
                   - Post Processing: fill_the_gaps; the images are saved in the principal folder;
                   - Create the submission on this image ;           IMPORTANT !!! : for the submission be aware that no file .png is present inside the folder except the ones 
										      generated by the code
     

3) Image_processing_pre_proc.ipynb: it contains the pre-processing functions ( image processing based) used for features extraction. This work has to be thought as a preamble of the real work	
				    which aims at finding informative features that can be used in our fit model (creation of the training set) 


4) feature_extraction.py: In this file there are the functions which create the training set in reference to the considerations made in “Image_processing_pre_proc.ipynb”. 
                                - create_train_table (n_rows,n_features):        Create a new table for train

				- add_feature(train_tx,new_column_feature):      Add a new column to the train matrix

				- extract_features(img) :                        Extract 6-dimensional features consisting of average RGB color as well as variance
				
				- extract_mean_RGB(img):                         Extract mean RGB of the patch

				- extract_variance_RGB(img):                     Extract variance RGB of the patch

  			        - get_spectrum(img_patches):                     Calculate the fft of the image

				- get_spectrum_grey(img_patches):                Calculate the fft of the grey scal patch

				- extract_mean_spectrum_grey(spectrum):          Extract the mean of the specturm  (grey scale patch)

				- extract_variance_spectrum_grey(spectrum):       Extract the variance of the spectrum (grey scale patch)


				- extract_mean_spectrum(spectrum):                Extract the mean of the specturm  ( RGB patch)

				- extract_variance_spectrum(spectrum):            Extract the variance of the specturm  ( RGB patch)


				 - extract_new_features(img_patches,n_features,…):     Extract features for a given set of patches according to the input parameters


				- extract_img_features(filename,n_features..) :       Extract features for a given image


5) feature_increase.py:   Here the functions to increase the training model once the features have been fixed;

			   -  add_ones(tx):                                        Add column of ones to the dataset tx

			   -  build_poly(x, degree):                               Returns the polynomial basis functions for input data x, for j=2 up to j=degree.



6) GMM_functions.py:     Here the functions to use GMM (unsupervised method) for enhance our dataset:
			
			   -label_to_img_GMM(imgwidth, imgheight, w, h, labels):     From a vector of labels ( label in this case means the class of a specific cluster)   this function returns  a 											      segmented image where each patch is  colored according to the class;

			   - build_new_X(Z_GMM,X,n_components):                     Adding the features obtained with GMM to X train matrix. 
										    METHOD for features extraction: 
										    -Given in input the X matrix and Z_GMM,a vector containing the label of the clusters (Z_GMM and X have the same length)
 											do the following :

									            - being S the set of ALL the patches which belong to the same label k , calculate the mean R,G,B and the variance R,G,B 
										       for S and add these values as feature of the patches of S. 
									            - do the same of the same for “mean grey” and “variance grey”
										    - for the mean_grey add also the difference between “mean grey” of the set S and the mean grey of the single patch;

7) helper_functions.py: it contains the  the functions useful for elaborate the images and visualize the results in the notebook 

			-load_image(infilename)

			-img_float_to_uint8(img)

			-concatenate_images(img, gt_img)

			-img_crop(im, w, h)

			-RGB_to_grey(image): 					     - transform the RGB into grey scale

			-value_to_class(v)

			-label_to_img(imgwidth, imgheight, w, h, labels)

			-make_img_overlay(img, predicted_img)

			-binary_to_uint8(img)


8) mask_to_submission.py : 							functions for creating the submission given the images







			            